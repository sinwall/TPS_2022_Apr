{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-30T00:34:40.974655Z",
     "iopub.status.busy": "2022-08-30T00:34:40.973673Z",
     "iopub.status.idle": "2022-08-30T00:34:41.013781Z",
     "shell.execute_reply": "2022-08-30T00:34:41.011745Z",
     "shell.execute_reply.started": "2022-08-30T00:34:40.974450Z"
    }
   },
   "outputs": [],
   "source": [
    "input_path = '../input/tabular-playground-series-apr-2022/'\n",
    "output_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T00:34:41.018288Z",
     "iopub.status.busy": "2022-08-30T00:34:41.016478Z",
     "iopub.status.idle": "2022-08-30T00:34:42.486287Z",
     "shell.execute_reply": "2022-08-30T00:34:42.484764Z",
     "shell.execute_reply.started": "2022-08-30T00:34:41.018207Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def load_raw_data(train_or_test='train'):\n",
    "    file_name = f'{input_path}/{train_or_test}.csv'\n",
    "    df = pd.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "def load_label(train_or_test='train'):\n",
    "    file_name = input_path + ('train_labels.csv' if train_or_test=='train' else 'sample_submission.csv')\n",
    "    df = pd.read_csv(file_name)\n",
    "    return df['state'].values\n",
    "\n",
    "def competition_metric(y_true, y_score):\n",
    "    return roc_auc_score(y_true, y_score)\n",
    "\n",
    "def evaluate(model, X, y):\n",
    "    return competition_metric(y, model.predict_proba(X)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T00:34:42.490099Z",
     "iopub.status.busy": "2022-08-30T00:34:42.489431Z",
     "iopub.status.idle": "2022-08-30T00:34:45.043983Z",
     "shell.execute_reply": "2022-08-30T00:34:45.042611Z",
     "shell.execute_reply.started": "2022-08-30T00:34:42.490036Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from scipy.stats import kurtosis\n",
    "from tsfresh.feature_extraction.extraction import extract_features\n",
    "\n",
    "class ElementaryExtractor(BaseEstimator, TransformerMixin):\n",
    "    features_to_use = ['med_abs_val_00',\n",
    "        'max_abs_val_00',\n",
    "        'sum_abs_diff_00',\n",
    "        'l2_sum_00',\n",
    "        'l2_sum_diff_00',\n",
    "        'l2_sum_diff2_00',\n",
    "        'kurt_00',\n",
    "        'sm_00',\n",
    "        'kurt_diff_00',\n",
    "        'mean_01',\n",
    "        'med_abs_val_01',\n",
    "        'l2_sum_diff2_01',\n",
    "        'sm_01',\n",
    "        'iqr_diff_01',\n",
    "        'mean_02',\n",
    "        'med_abs_val_02',\n",
    "        'max_abs_val_02',\n",
    "        'med_abs_diff_02',\n",
    "        'max_abs_diff_02',\n",
    "        'l2_sum_diff_02',\n",
    "        'l2_sum_diff2_02',\n",
    "        'std_02',\n",
    "        'kurt_02',\n",
    "        'std_diff_02',\n",
    "        'iqr_diff_02',\n",
    "        'kurt_diff_02',\n",
    "        'med_abs_val_03',\n",
    "        'med_abs_diff_03',\n",
    "        'max_abs_diff_03',\n",
    "        'sum_abs_diff_03',\n",
    "        'sm_03',\n",
    "        'iqr_diff_03',\n",
    "        'mean_04',\n",
    "        'med_abs_val_04',\n",
    "        'max_abs_val_04',\n",
    "        'med_abs_diff_04',\n",
    "        'max_abs_diff_04',\n",
    "        'l2_sum_04',\n",
    "        'l2_sum_diff2_04',\n",
    "        'iqr_04',\n",
    "        'kurt_04',\n",
    "        'sm_04',\n",
    "        'kurt_diff_04',\n",
    "        'mean_05',\n",
    "        'med_abs_diff_05',\n",
    "        'sum_abs_diff_05',\n",
    "        'sm_05',\n",
    "        'mean_06',\n",
    "        'med_abs_val_06',\n",
    "        'med_abs_diff_06',\n",
    "        'max_abs_diff_06',\n",
    "        'l2_sum_diff2_06',\n",
    "        'kurt_06',\n",
    "        'iqr_diff_06',\n",
    "        'kurt_diff_06',\n",
    "        'med_abs_val_07',\n",
    "        'sum_abs_diff_07',\n",
    "        'l2_sum_07',\n",
    "        'l2_sum_diff_07',\n",
    "        'l2_sum_diff2_07',\n",
    "        'iqr_07',\n",
    "        'sm_07',\n",
    "        'iqr_diff_07',\n",
    "        'kurt_diff_07',\n",
    "        'max_abs_diff_08',\n",
    "        'sum_abs_diff_08',\n",
    "        'l2_sum_08',\n",
    "        'l2_sum_diff_08',\n",
    "        'l2_sum_diff2_08',\n",
    "        'iqr_08',\n",
    "        'kurt_08',\n",
    "        'iqr_diff_08',\n",
    "        'kurt_diff_08',\n",
    "        'mean_09',\n",
    "        'max_abs_diff_09',\n",
    "        'sum_abs_diff_09',\n",
    "        'l2_sum_09',\n",
    "        'l2_sum_diff2_09',\n",
    "        'sm_09',\n",
    "        'iqr_diff_09',\n",
    "        'kurt_diff_09',\n",
    "        'mean_10',\n",
    "        'med_abs_val_10',\n",
    "        'max_abs_diff_10',\n",
    "        'l2_sum_diff2_10',\n",
    "        'std_10',\n",
    "        'kurt_10',\n",
    "        'sm_10',\n",
    "        'std_diff_10',\n",
    "        'kurt_diff_10',\n",
    "        'mean_11',\n",
    "        'sum_abs_diff_11',\n",
    "        'l2_sum_diff_11',\n",
    "        'sm_11',\n",
    "        'iqr_diff_11',\n",
    "        'kurt_diff_11',\n",
    "        'max_abs_diff_12',\n",
    "        'sum_abs_diff_12',\n",
    "        'l2_sum_12',\n",
    "        'l2_sum_diff2_12',\n",
    "        'iqr_12',\n",
    "        'kurt_12',\n",
    "        'sm_12',\n",
    "        'kurt_diff_12',\n",
    "        'up_sum_02',\n",
    "        'up_max_02',\n",
    "        'up_mean_02',\n",
    "        'down_count_02']\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        seq_no = X['sequence'].iloc[::60]\n",
    "        x = X.loc[:, 'sensor_00':'sensor_12'].values.reshape(-1, 60, 13)\n",
    "        features = dict()\n",
    "        for i in range(13):\n",
    "            channel = x[:, :, i]\n",
    "            # mean\n",
    "            features[f'mean_{i:0>2}'] = np.mean(channel, axis=1)\n",
    "            # median of absolute values\n",
    "            features[f'med_abs_val_{i:0>2}'] = np.median(np.abs(channel), axis=1)\n",
    "            # maximum of absolute values\n",
    "            features[f'max_abs_val_{i:0>2}'] = np.max(np.abs(channel), axis=1)\n",
    "            #median of absolute diff\n",
    "            features[f'med_abs_diff_{i:0>2}'] = np.median(np.abs(np.diff(channel, axis=1)), axis=1)\n",
    "            # maximum of absolute diff\n",
    "            features[f'max_abs_diff_{i:0>2}'] = np.max(np.abs(np.diff(channel, axis=1)), axis=1)\n",
    "            # absolute sum of difference\n",
    "            features[f'sum_abs_diff_{i:0>2}'] = np.sum(np.abs(np.diff(channel, axis=1)), axis=1)\n",
    "            # square sum\n",
    "            features[f'l2_sum_{i:0>2}'] = np.linalg.norm(channel, axis=1)\n",
    "            # square sum of difference\n",
    "            features[f'l2_sum_diff_{i:0>2}'] = np.linalg.norm(np.diff(channel, axis=1), axis=1)\n",
    "            # square sum of 2-diff\n",
    "            features[f'l2_sum_diff2_{i:0>2}'] = np.linalg.norm(np.diff(np.diff(channel, axis=1), axis=1), axis=1)\n",
    "            # standard deviation\n",
    "            features[f'std_{i:0>2}'] = np.std(channel, axis=1)\n",
    "            features[f'iqr_{i:0>2}'] = np.quantile(channel, 0.75, axis=1) - np.quantile(channel, 0.25, axis=1)\n",
    "            features[f'kurt_{i:0>2}'] = kurtosis(channel, axis=1)\n",
    "            features[f'sm_{i:0>2}'] = np.nan_to_num(features[f'std_{i:0>2}'] / np.abs(np.mean(channel, axis=1))).clip(-1e30, 1e30)\n",
    "\n",
    "            features[f'std_diff_{i:0>2}'] = np.std(np.diff(channel, axis=1), axis=1)\n",
    "            features[f'iqr_diff_{i:0>2}'] = np.quantile(np.diff(channel, axis=1), 0.75, axis=1) - np.quantile(np.diff(channel, axis=1), 0.25, axis=1)\n",
    "            features[f'kurt_diff_{i:0>2}'] = kurtosis(np.diff(channel, axis=1), axis=1)\n",
    "\n",
    "        sensor_02 = x[:, :, 2]\n",
    "        features[f'up_count_02'] = np.sum(np.diff(sensor_02, axis=1) >= 0, axis=1)\n",
    "        features[f'up_sum_02'] = np.sum(np.clip(np.diff(sensor_02, axis=1), 0, None), axis=1)\n",
    "        features[f'up_max_02'] = np.max(np.clip(np.diff(sensor_02, axis=1), 0, None), axis=1)\n",
    "        features[f'up_mean_02'] = np.nan_to_num(features[f'up_max_02'] / features[f'up_count_02'], posinf=40)\n",
    "\n",
    "        features[f'down_count_02'] = np.sum(np.diff(sensor_02, axis=1) < 0, axis=1)\n",
    "        features[f'down_sum_02'] = np.sum(np.clip(np.diff(sensor_02, axis=1), None, 0), axis=1)\n",
    "        features[f'down_min_02'] = np.sum(np.clip(np.diff(sensor_02, axis=1), None, 0), axis=1)\n",
    "        features[f'down_mean_02'] = np.nan_to_num(features[f'down_min_02'] / features[f'down_count_02'], neginf=-40)\n",
    "        \n",
    "        return pd.DataFrame(features, index=seq_no)[self.features_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-30T00:34:45.062512Z",
     "iopub.status.busy": "2022-08-30T00:34:45.059840Z",
     "iopub.status.idle": "2022-08-30T01:05:26.133265Z",
     "shell.execute_reply": "2022-08-30T01:05:26.126951Z",
     "shell.execute_reply.started": "2022-08-30T00:34:45.062318Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from MyFeatureExtractor import MyFeatureExtractor\n",
    "\n",
    "df = load_raw_data('train')\n",
    "y = load_label('train')\n",
    "\n",
    "def group_splitter(df, y, nfold=5, random_state=None):\n",
    "    subject_nums = df['subject'].unique()\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    subject_to_setnum = rng.integers(0, nfold, subject_nums.shape[0])\n",
    "    for i in range(nfold):\n",
    "        val_subjects = subject_nums[subject_to_setnum == i]\n",
    "        mask_df_val = df['subject'].isin(val_subjects)\n",
    "        mask_y_val = mask_df_val.iloc[::60]\n",
    "        yield df[~mask_df_val], df[mask_df_val], y[~mask_y_val], y[mask_y_val]\n",
    "    \n",
    "for df_train, df_val, y_train, y_val in group_splitter(df, y, nfold=5, random_state=42):\n",
    "    extractors = [ElementaryExtractor(), MyFeatureExtractor()]\n",
    "    X_train = pd.concat([extractor.fit_transform(df_train) for extractor in extractors], axis=1)\n",
    "    X_val = pd.concat([extractor.transform(df_val) for extractor in extractors], axis=1)\n",
    "    \n",
    "    clf = LGBMClassifier(num_leaves=31, max_depth=-1, n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train.values, y_train)\n",
    "    print(evaluate(clf, X_train, y_train))\n",
    "    print(evaluate(clf, X_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
