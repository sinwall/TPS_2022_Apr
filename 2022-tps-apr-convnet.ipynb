{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sogamja/2022-tps-apr-convnet?scriptVersionId=105928568\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"84cc23ef","metadata":{"papermill":{"duration":0.003702,"end_time":"2022-09-18T06:11:40.149327","exception":false,"start_time":"2022-09-18T06:11:40.145625","status":"completed"},"tags":[]},"source":["# Uses skip connection\n","https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec"]},{"cell_type":"code","execution_count":1,"id":"520bcf3d","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-18T06:11:40.156628Z","iopub.status.busy":"2022-09-18T06:11:40.155997Z","iopub.status.idle":"2022-09-18T06:11:40.164581Z","shell.execute_reply":"2022-09-18T06:11:40.163958Z"},"papermill":{"duration":0.014472,"end_time":"2022-09-18T06:11:40.16655","exception":false,"start_time":"2022-09-18T06:11:40.152078","status":"completed"},"tags":[]},"outputs":[],"source":["input_path = '../input/tabular-playground-series-apr-2022/'\n","output_path = './'"]},{"cell_type":"code","execution_count":2,"id":"230ad5b8","metadata":{"execution":{"iopub.execute_input":"2022-09-18T06:11:40.173159Z","iopub.status.busy":"2022-09-18T06:11:40.172427Z","iopub.status.idle":"2022-09-18T06:11:41.232331Z","shell.execute_reply":"2022-09-18T06:11:41.231348Z"},"papermill":{"duration":1.065636,"end_time":"2022-09-18T06:11:41.234744","exception":false,"start_time":"2022-09-18T06:11:40.169108","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import roc_auc_score\n","\n","def load_raw_data(train_or_test='train'):\n","    file_name = f'{input_path}/{train_or_test}.csv'\n","    df = pd.read_csv(file_name)\n","    return df\n","\n","def load_label(train_or_test='train'):\n","    file_name = input_path + ('train_labels.csv' if train_or_test=='train' else 'sample_submission.csv')\n","    df = pd.read_csv(file_name)\n","    return df['state'].values\n","\n","def competition_metric(y_true, y_score):\n","    return roc_auc_score(y_true, y_score)\n","\n","def evaluate(model, X, y):\n","    return competition_metric(y, model.predict_proba(X)[:, 1])\n","\n","def submit(arr):\n","    df = pd.read_csv(f'{input_path}/sample_submission.csv')\n","    df['state'] = arr\n","    df.to_csv(f'{output_path}/submission.csv', index=False)"]},{"cell_type":"code","execution_count":3,"id":"b1691918","metadata":{"execution":{"iopub.execute_input":"2022-09-18T06:11:41.241751Z","iopub.status.busy":"2022-09-18T06:11:41.241273Z","iopub.status.idle":"2022-09-18T06:11:47.118042Z","shell.execute_reply":"2022-09-18T06:11:47.117059Z"},"papermill":{"duration":5.883065,"end_time":"2022-09-18T06:11:47.12047","exception":false,"start_time":"2022-09-18T06:11:41.237405","status":"completed"},"tags":[]},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.base import BaseEstimator, TransformerMixin\n","\n","class ResNetModel(keras.Model):\n","    def __init__(self):\n","        super(ResNetModel, self).__init__()\n","        self.fns = [\n","            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)), \n","            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n","            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n","            keras.layers.AveragePooling1D(2),\n","            \n","            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n","            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n","            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n","            keras.layers.AveragePooling1D(2),\n","            \n","            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n","            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n","            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n","            keras.layers.AveragePooling1D(3),\n","            \n","            keras.layers.GlobalAveragePooling1D(),\n","            keras.layers.Dense(1, activation='sigmoid')\n","        ]\n","        self.bns = [\n","            keras.layers.BatchNormalization(), \n","            keras.layers.BatchNormalization(), \n","            \n","            keras.layers.BatchNormalization(), \n","            keras.layers.BatchNormalization(), \n","            \n","            keras.layers.BatchNormalization(), \n","            keras.layers.BatchNormalization(), \n","            \n","            keras.layers.BatchNormalization(), \n","            keras.layers.BatchNormalization(), \n","        ]\n","        \n","    def call(self, inputs):\n","        outputs = inputs\n","        \n","        outputs = self.fns[0](outputs)\n","        res = outputs\n","        res = self.fns[1](res)\n","        res = self.fns[2](res)\n","        outputs += res\n","        outputs = self.fns[3](outputs)\n","        \n","        outputs = self.fns[4](outputs)\n","        res = outputs\n","        res = self.fns[5](res)\n","        res = self.fns[6](res)\n","        outputs += res\n","        outputs = self.fns[7](outputs)\n","        \n","        outputs = self.fns[8](outputs)\n","        res = outputs\n","        res = self.fns[9](res)\n","        res = self.fns[10](res)\n","        outputs += res\n","        outputs = self.fns[11](outputs)\n","        \n","        outputs = self.fns[-2](outputs)\n","        outputs = self.fns[-1](outputs)\n","        \n","        return outputs\n","    \n","    def predict_proba(self, X):\n","        return np.concatenate([1-self.predict(X), self.predict(X)], axis=1)\n","\n","def random_sensor_swap(x, y, random_state=None):\n","    rng = np.random.default_rng(random_state)\n","    p_swap = 0.5\n","    indices = rng.choice(np.arange(x.shape[0]), int(p_swap*x.shape[0]), replace=False)\n","    x_aug, y_aug = x[indices], y[indices]\n","    swap_codes = rng.integers(0, 13, (x_aug.shape[0], 2))\n","    for i in range(x_aug.shape[0]):\n","        a, b = swap_codes[i]\n","        x_aug[i, :, [a, b]] = x_aug[i, :, [b, a]]\n","    x = np.concatenate([x, x_aug], axis=0)\n","    y = np.concatenate([y, y_aug], axis=0)\n","    return x, y\n","\n","def group_splitter(df, nfold=5, random_state=None):\n","    subject_nums = df['subject'].unique()\n","    rng = np.random.default_rng(random_state)\n","    subject_to_setnum = rng.integers(0, nfold, subject_nums.shape[0])\n","    for i in range(nfold):\n","        val_subjects = subject_nums[subject_to_setnum == i]\n","        mask_df_val = df['subject'].isin(val_subjects)\n","        mask_y_val = mask_df_val.iloc[::60]\n","        yield mask_df_val, mask_y_val\n","\n","\n","class DF2arr(BaseEstimator, TransformerMixin):\n","    def fit(self, X, y=None):\n","        return self\n","    \n","    def transform(self, X, y=None):\n","        return X.loc[:, 'sensor_00':'sensor_12'].values.reshape(-1, 60, 13)\n","    \n","    \n","class MyPreprocessor(BaseEstimator, TransformerMixin):\n","    def fit(self, X, y=None):\n","        return self\n","    \n","    def transform(self, X, y=None):\n","        X = normalize(X)\n","        return X\n","    \n","def normalize(x):\n","    x = x / (np.linalg.norm(x, axis=1, keepdims=True) + 1e-10)\n","    return x"]},{"cell_type":"code","execution_count":4,"id":"b244497b","metadata":{"execution":{"iopub.execute_input":"2022-09-18T06:11:47.127309Z","iopub.status.busy":"2022-09-18T06:11:47.126639Z","iopub.status.idle":"2022-09-18T07:18:42.008308Z","shell.execute_reply":"2022-09-18T07:18:42.00691Z"},"papermill":{"duration":4014.887871,"end_time":"2022-09-18T07:18:42.010997","exception":false,"start_time":"2022-09-18T06:11:47.123126","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-18 06:11:59.356012: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","2022-09-18 06:11:59.572525: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["0.9640761214353601\n","              precision    recall  f1-score   support\n","\n","           0     0.9014    0.9032    0.9023      2592\n","           1     0.9017    0.9000    0.9008      2559\n","\n","    accuracy                         0.9016      5151\n","   macro avg     0.9016    0.9016    0.9016      5151\n","weighted avg     0.9016    0.9016    0.9016      5151\n","\n","0.9390609822401481\n","              precision    recall  f1-score   support\n","\n","           0     0.8626    0.8951    0.8785      2412\n","           1     0.8793    0.8427    0.8606      2187\n","\n","    accuracy                         0.8702      4599\n","   macro avg     0.8709    0.8689    0.8696      4599\n","weighted avg     0.8705    0.8702    0.8700      4599\n","\n","0.9630005013028857\n","              precision    recall  f1-score   support\n","\n","           0     0.8847    0.8939    0.8892      2789\n","           1     0.9071    0.8989    0.9030      3215\n","\n","    accuracy                         0.8966      6004\n","   macro avg     0.8959    0.8964    0.8961      6004\n","weighted avg     0.8967    0.8966    0.8966      6004\n","\n","0.9428196533065782\n","              precision    recall  f1-score   support\n","\n","           0     0.8800    0.8381    0.8586      2564\n","           1     0.8524    0.8911    0.8713      2690\n","\n","    accuracy                         0.8652      5254\n","   macro avg     0.8662    0.8646    0.8649      5254\n","weighted avg     0.8659    0.8652    0.8651      5254\n","\n","0.9500405021517226\n","              precision    recall  f1-score   support\n","\n","           0     0.8960    0.8595    0.8774      2597\n","           1     0.8522    0.8904    0.8709      2363\n","\n","    accuracy                         0.8742      4960\n","   macro avg     0.8741    0.8749    0.8741      4960\n","weighted avg     0.8751    0.8742    0.8743      4960\n","\n","5-fold CV score: 0.9518\n"]}],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.metrics import classification_report\n","cv_scores = []\n","\n","df = load_raw_data('train')\n","X = DF2arr().transform(df)\n","y = load_label('train')\n","subj_nums = df['subject']\n","\n","preprocessor = make_pipeline(DF2arr(), MyPreprocessor())\n","\n","keras.backend.clear_session()\n","tf.random.set_seed(42)\n","callbacks = [\n","    keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)\n","]\n","\n","for mask_df_val, mask_y_val in group_splitter(df, nfold=5, random_state=42):\n","    df_train, df_val = df[~mask_df_val], df[mask_df_val]\n","    y_train, y_val = y[~mask_y_val], y[mask_y_val]\n","    for mask_df_v, mask_y_v in group_splitter(df_train, nfold=5, random_state=42):\n","        df_t, df_v = df_train[~mask_df_v], df_train[mask_df_v]\n","        y_t, y_v = y_train[~mask_y_v], y_train[mask_y_v]\n","\n","    X_t = preprocessor.fit_transform(df_t)\n","    X_v = preprocessor.transform(df_v)\n","    X_val = preprocessor.transform(df_val)\n","\n","\n","    model = ResNetModel()\n","    model.compile(\n","        loss='binary_crossentropy', \n","        metrics=['AUC'],\n","        optimizer=keras.optimizers.Adam(1e-3))\n","    model.fit(\n","        X_t, y_t, \n","        batch_size=1024,\n","        epochs=500, \n","        callbacks=callbacks,\n","        validation_data=(X_v, y_v),\n","        verbose=0,\n","    )\n","    print(evaluate(model, X_val, y_val))\n","    print(classification_report(y_val, (model.predict(X_val) >= 0.5).astype(int), digits=4 ))\n","    \n","    cv_scores.append(evaluate(model, X_val, y_val))\n","print(f'5-fold CV score: {np.mean(cv_scores):.4f}')"]},{"cell_type":"code","execution_count":5,"id":"26dbd43f","metadata":{"execution":{"iopub.execute_input":"2022-09-18T07:18:42.019999Z","iopub.status.busy":"2022-09-18T07:18:42.019597Z","iopub.status.idle":"2022-09-18T07:28:44.367737Z","shell.execute_reply":"2022-09-18T07:28:44.366888Z"},"papermill":{"duration":602.355188,"end_time":"2022-09-18T07:28:44.370155","exception":false,"start_time":"2022-09-18T07:18:42.014967","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.3089 - auc: 0.9614 - val_loss: 0.3444 - val_auc: 0.9497\n","Epoch 2/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.3081 - auc: 0.9615 - val_loss: 0.3543 - val_auc: 0.9507\n","Epoch 3/500\n","21/21 [==============================] - 3s 156ms/step - loss: 0.3072 - auc: 0.9618 - val_loss: 0.3388 - val_auc: 0.9516\n","Epoch 4/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.3055 - auc: 0.9624 - val_loss: 0.3422 - val_auc: 0.9516\n","Epoch 5/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.3049 - auc: 0.9625 - val_loss: 0.3423 - val_auc: 0.9501\n","Epoch 6/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.3048 - auc: 0.9626 - val_loss: 0.3505 - val_auc: 0.9479\n","Epoch 7/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.3069 - auc: 0.9619 - val_loss: 0.3407 - val_auc: 0.9511\n","Epoch 8/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.3051 - auc: 0.9625 - val_loss: 0.3399 - val_auc: 0.9518\n","Epoch 9/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.3033 - auc: 0.9630 - val_loss: 0.3392 - val_auc: 0.9512\n","Epoch 10/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.3030 - auc: 0.9631 - val_loss: 0.3433 - val_auc: 0.9511\n","Epoch 11/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.3028 - auc: 0.9632 - val_loss: 0.3395 - val_auc: 0.9517\n","Epoch 12/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.3006 - auc: 0.9639 - val_loss: 0.3416 - val_auc: 0.9509\n","Epoch 13/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.3037 - auc: 0.9630 - val_loss: 0.3380 - val_auc: 0.9523\n","Epoch 14/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.3017 - auc: 0.9635 - val_loss: 0.3414 - val_auc: 0.9518\n","Epoch 15/500\n","21/21 [==============================] - 3s 153ms/step - loss: 0.3014 - auc: 0.9636 - val_loss: 0.3464 - val_auc: 0.9493\n","Epoch 16/500\n","21/21 [==============================] - 3s 121ms/step - loss: 0.3025 - auc: 0.9633 - val_loss: 0.3398 - val_auc: 0.9512\n","Epoch 17/500\n","21/21 [==============================] - 3s 123ms/step - loss: 0.3004 - auc: 0.9640 - val_loss: 0.3478 - val_auc: 0.9508\n","Epoch 18/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.3019 - auc: 0.9635 - val_loss: 0.3362 - val_auc: 0.9529\n","Epoch 19/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2992 - auc: 0.9644 - val_loss: 0.3376 - val_auc: 0.9526\n","Epoch 20/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2991 - auc: 0.9644 - val_loss: 0.3436 - val_auc: 0.9512\n","Epoch 21/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.3016 - auc: 0.9637 - val_loss: 0.3359 - val_auc: 0.9530\n","Epoch 22/500\n","21/21 [==============================] - 3s 118ms/step - loss: 0.3029 - auc: 0.9632 - val_loss: 0.3404 - val_auc: 0.9520\n","Epoch 23/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2991 - auc: 0.9643 - val_loss: 0.3424 - val_auc: 0.9522\n","Epoch 24/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2985 - auc: 0.9646 - val_loss: 0.3426 - val_auc: 0.9508\n","Epoch 25/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.3011 - auc: 0.9638 - val_loss: 0.3543 - val_auc: 0.9480\n","Epoch 26/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.3009 - auc: 0.9638 - val_loss: 0.3414 - val_auc: 0.9530\n","Epoch 27/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2975 - auc: 0.9649 - val_loss: 0.3434 - val_auc: 0.9511\n","Epoch 28/500\n","21/21 [==============================] - 3s 156ms/step - loss: 0.2972 - auc: 0.9650 - val_loss: 0.3387 - val_auc: 0.9524\n","Epoch 29/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2970 - auc: 0.9651 - val_loss: 0.3437 - val_auc: 0.9505\n","Epoch 30/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.2966 - auc: 0.9652 - val_loss: 0.3397 - val_auc: 0.9518\n","Epoch 31/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2965 - auc: 0.9653 - val_loss: 0.3550 - val_auc: 0.9522\n","Epoch 32/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2967 - auc: 0.9652 - val_loss: 0.3380 - val_auc: 0.9525\n","Epoch 33/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2972 - auc: 0.9651 - val_loss: 0.3484 - val_auc: 0.9509\n","Epoch 34/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2954 - auc: 0.9656 - val_loss: 0.3578 - val_auc: 0.9505\n","Epoch 35/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2985 - auc: 0.9647 - val_loss: 0.3376 - val_auc: 0.9526\n","Epoch 36/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2957 - auc: 0.9654 - val_loss: 0.3439 - val_auc: 0.9513\n","Epoch 37/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2947 - auc: 0.9658 - val_loss: 0.3349 - val_auc: 0.9538\n","Epoch 38/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2929 - auc: 0.9663 - val_loss: 0.3407 - val_auc: 0.9516\n","Epoch 39/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2960 - auc: 0.9655 - val_loss: 0.3487 - val_auc: 0.9490\n","Epoch 40/500\n","21/21 [==============================] - 3s 154ms/step - loss: 0.2950 - auc: 0.9658 - val_loss: 0.3397 - val_auc: 0.9521\n","Epoch 41/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2911 - auc: 0.9670 - val_loss: 0.3388 - val_auc: 0.9531\n","Epoch 42/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2913 - auc: 0.9669 - val_loss: 0.3383 - val_auc: 0.9525\n","Epoch 43/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2906 - auc: 0.9671 - val_loss: 0.3405 - val_auc: 0.9522\n","Epoch 44/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2905 - auc: 0.9672 - val_loss: 0.3509 - val_auc: 0.9487\n","Epoch 45/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2982 - auc: 0.9649 - val_loss: 0.3398 - val_auc: 0.9527\n","Epoch 46/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2904 - auc: 0.9672 - val_loss: 0.3365 - val_auc: 0.9535\n","Epoch 47/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2977 - auc: 0.9651 - val_loss: 0.3453 - val_auc: 0.9508\n","Epoch 48/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2989 - auc: 0.9647 - val_loss: 0.3471 - val_auc: 0.9494\n","Epoch 49/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2914 - auc: 0.9669 - val_loss: 0.3368 - val_auc: 0.9533\n","Epoch 50/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2911 - auc: 0.9671 - val_loss: 0.3451 - val_auc: 0.9516\n","Epoch 51/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2941 - auc: 0.9662 - val_loss: 0.3570 - val_auc: 0.9510\n","Epoch 52/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2944 - auc: 0.9661 - val_loss: 0.3387 - val_auc: 0.9529\n","Epoch 53/500\n","21/21 [==============================] - 3s 154ms/step - loss: 0.2893 - auc: 0.9676 - val_loss: 0.3353 - val_auc: 0.9536\n","Epoch 54/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2896 - auc: 0.9676 - val_loss: 0.3458 - val_auc: 0.9504\n","Epoch 55/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2886 - auc: 0.9678 - val_loss: 0.3369 - val_auc: 0.9534\n","Epoch 56/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2915 - auc: 0.9670 - val_loss: 0.3414 - val_auc: 0.9516\n","Epoch 57/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2891 - auc: 0.9677 - val_loss: 0.3486 - val_auc: 0.9519\n","Epoch 58/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2924 - auc: 0.9667 - val_loss: 0.3597 - val_auc: 0.9522\n","Epoch 59/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2938 - auc: 0.9665 - val_loss: 0.3380 - val_auc: 0.9532\n","Epoch 60/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2932 - auc: 0.9666 - val_loss: 0.3387 - val_auc: 0.9531\n","Epoch 61/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2891 - auc: 0.9678 - val_loss: 0.3476 - val_auc: 0.9499\n","Epoch 62/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2888 - auc: 0.9680 - val_loss: 0.3427 - val_auc: 0.9526\n","Epoch 63/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2845 - auc: 0.9691 - val_loss: 0.3406 - val_auc: 0.9532\n","Epoch 64/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2845 - auc: 0.9691 - val_loss: 0.3462 - val_auc: 0.9507\n","Epoch 65/500\n","21/21 [==============================] - 3s 157ms/step - loss: 0.2876 - auc: 0.9683 - val_loss: 0.3450 - val_auc: 0.9521\n","Epoch 66/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2864 - auc: 0.9687 - val_loss: 0.3408 - val_auc: 0.9528\n","Epoch 67/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2896 - auc: 0.9677 - val_loss: 0.3404 - val_auc: 0.9526\n","Epoch 68/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2907 - auc: 0.9675 - val_loss: 0.3424 - val_auc: 0.9519\n","Epoch 69/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2854 - auc: 0.9690 - val_loss: 0.3412 - val_auc: 0.9532\n","Epoch 70/500\n","21/21 [==============================] - 3s 122ms/step - loss: 0.2867 - auc: 0.9687 - val_loss: 0.3468 - val_auc: 0.9517\n","Epoch 71/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2890 - auc: 0.9680 - val_loss: 0.3442 - val_auc: 0.9536\n","Epoch 72/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2868 - auc: 0.9686 - val_loss: 0.3434 - val_auc: 0.9526\n","Epoch 73/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2840 - auc: 0.9694 - val_loss: 0.3485 - val_auc: 0.9501\n","Epoch 74/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2851 - auc: 0.9691 - val_loss: 0.3426 - val_auc: 0.9523\n","Epoch 75/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2853 - auc: 0.9690 - val_loss: 0.3407 - val_auc: 0.9526\n","Epoch 76/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2829 - auc: 0.9698 - val_loss: 0.3448 - val_auc: 0.9525\n","Epoch 77/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2851 - auc: 0.9692 - val_loss: 0.3533 - val_auc: 0.9511\n","Epoch 78/500\n","21/21 [==============================] - 3s 155ms/step - loss: 0.2882 - auc: 0.9683 - val_loss: 0.3428 - val_auc: 0.9521\n","Epoch 79/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2835 - auc: 0.9697 - val_loss: 0.3561 - val_auc: 0.9504\n","Epoch 80/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2854 - auc: 0.9691 - val_loss: 0.3477 - val_auc: 0.9515\n","Epoch 81/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2850 - auc: 0.9693 - val_loss: 0.3531 - val_auc: 0.9515\n","Epoch 82/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2842 - auc: 0.9695 - val_loss: 0.3473 - val_auc: 0.9512\n","Epoch 83/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2846 - auc: 0.9694 - val_loss: 0.3528 - val_auc: 0.9520\n","Epoch 84/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2879 - auc: 0.9685 - val_loss: 0.3408 - val_auc: 0.9532\n","Epoch 85/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2831 - auc: 0.9699 - val_loss: 0.3446 - val_auc: 0.9527\n","Epoch 86/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2827 - auc: 0.9700 - val_loss: 0.3480 - val_auc: 0.9512\n","Epoch 87/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2829 - auc: 0.9700 - val_loss: 0.3468 - val_auc: 0.9515\n","Epoch 88/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2851 - auc: 0.9693 - val_loss: 0.3495 - val_auc: 0.9501\n","Epoch 89/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2813 - auc: 0.9704 - val_loss: 0.3477 - val_auc: 0.9525\n","Epoch 90/500\n","21/21 [==============================] - 3s 154ms/step - loss: 0.2853 - auc: 0.9694 - val_loss: 0.3492 - val_auc: 0.9530\n","Epoch 91/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2837 - auc: 0.9699 - val_loss: 0.3544 - val_auc: 0.9496\n","Epoch 92/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.2869 - auc: 0.9689 - val_loss: 0.3645 - val_auc: 0.9475\n","Epoch 93/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2878 - auc: 0.9688 - val_loss: 0.3431 - val_auc: 0.9527\n","Epoch 94/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2809 - auc: 0.9707 - val_loss: 0.3463 - val_auc: 0.9514\n","Epoch 95/500\n","21/21 [==============================] - 3s 117ms/step - loss: 0.2796 - auc: 0.9710 - val_loss: 0.3481 - val_auc: 0.9525\n","Epoch 96/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2795 - auc: 0.9711 - val_loss: 0.3459 - val_auc: 0.9520\n","Epoch 97/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2799 - auc: 0.9710 - val_loss: 0.3408 - val_auc: 0.9537\n","Epoch 98/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2786 - auc: 0.9714 - val_loss: 0.3480 - val_auc: 0.9522\n","Epoch 99/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2819 - auc: 0.9705 - val_loss: 0.3455 - val_auc: 0.9520\n","Epoch 100/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2828 - auc: 0.9703 - val_loss: 0.3504 - val_auc: 0.9517\n","Epoch 101/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2798 - auc: 0.9711 - val_loss: 0.3507 - val_auc: 0.9520\n","Epoch 102/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2816 - auc: 0.9706 - val_loss: 0.3490 - val_auc: 0.9518\n","Epoch 103/500\n","21/21 [==============================] - 3s 158ms/step - loss: 0.2852 - auc: 0.9697 - val_loss: 0.3548 - val_auc: 0.9506\n","Epoch 104/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.2803 - auc: 0.9710 - val_loss: 0.3501 - val_auc: 0.9514\n","Epoch 105/500\n","21/21 [==============================] - 3s 122ms/step - loss: 0.2813 - auc: 0.9708 - val_loss: 0.3528 - val_auc: 0.9526\n","Epoch 106/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2779 - auc: 0.9718 - val_loss: 0.3480 - val_auc: 0.9519\n","Epoch 107/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2783 - auc: 0.9717 - val_loss: 0.3565 - val_auc: 0.9494\n","Epoch 108/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2794 - auc: 0.9714 - val_loss: 0.3451 - val_auc: 0.9529\n","Epoch 109/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2797 - auc: 0.9713 - val_loss: 0.3524 - val_auc: 0.9528\n","Epoch 110/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2785 - auc: 0.9717 - val_loss: 0.3438 - val_auc: 0.9535\n","Epoch 111/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2763 - auc: 0.9722 - val_loss: 0.3497 - val_auc: 0.9514\n","Epoch 112/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2828 - auc: 0.9705 - val_loss: 0.3450 - val_auc: 0.9527\n","Epoch 113/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2764 - auc: 0.9723 - val_loss: 0.3517 - val_auc: 0.9510\n","Epoch 114/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2791 - auc: 0.9716 - val_loss: 0.3629 - val_auc: 0.9510\n","Epoch 115/500\n","21/21 [==============================] - 3s 156ms/step - loss: 0.2871 - auc: 0.9695 - val_loss: 0.3526 - val_auc: 0.9509\n","Epoch 116/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2810 - auc: 0.9711 - val_loss: 0.3700 - val_auc: 0.9518\n","Epoch 117/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2799 - auc: 0.9714 - val_loss: 0.3508 - val_auc: 0.9522\n","Epoch 118/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2761 - auc: 0.9725 - val_loss: 0.3574 - val_auc: 0.9506\n","Epoch 119/500\n","21/21 [==============================] - 3s 121ms/step - loss: 0.2757 - auc: 0.9726 - val_loss: 0.3457 - val_auc: 0.9534\n","Epoch 120/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2785 - auc: 0.9719 - val_loss: 0.3454 - val_auc: 0.9532\n","Epoch 121/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2749 - auc: 0.9728 - val_loss: 0.3511 - val_auc: 0.9521\n","Epoch 122/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2813 - auc: 0.9712 - val_loss: 0.3541 - val_auc: 0.9514\n","Epoch 123/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2809 - auc: 0.9713 - val_loss: 0.3560 - val_auc: 0.9513\n","Epoch 124/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2807 - auc: 0.9713 - val_loss: 0.3438 - val_auc: 0.9535\n","Epoch 125/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2748 - auc: 0.9730 - val_loss: 0.3522 - val_auc: 0.9509\n","Epoch 126/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2739 - auc: 0.9734 - val_loss: 0.3566 - val_auc: 0.9517\n","Epoch 127/500\n","21/21 [==============================] - 3s 155ms/step - loss: 0.2734 - auc: 0.9734 - val_loss: 0.3480 - val_auc: 0.9528\n","Epoch 128/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2749 - auc: 0.9730 - val_loss: 0.3496 - val_auc: 0.9530\n","Epoch 129/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2739 - auc: 0.9733 - val_loss: 0.3544 - val_auc: 0.9515\n","Epoch 130/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2766 - auc: 0.9726 - val_loss: 0.3539 - val_auc: 0.9515\n","Epoch 131/500\n","21/21 [==============================] - 3s 124ms/step - loss: 0.2779 - auc: 0.9723 - val_loss: 0.3511 - val_auc: 0.9521\n","Epoch 132/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2758 - auc: 0.9728 - val_loss: 0.3522 - val_auc: 0.9531\n","Epoch 133/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2762 - auc: 0.9728 - val_loss: 0.3584 - val_auc: 0.9519\n","Epoch 134/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2762 - auc: 0.9728 - val_loss: 0.3502 - val_auc: 0.9528\n","Epoch 135/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2739 - auc: 0.9734 - val_loss: 0.3474 - val_auc: 0.9536\n","Epoch 136/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.2745 - auc: 0.9733 - val_loss: 0.3606 - val_auc: 0.9510\n","Epoch 137/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2776 - auc: 0.9725 - val_loss: 0.3582 - val_auc: 0.9496\n","Epoch 138/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2739 - auc: 0.9735 - val_loss: 0.3528 - val_auc: 0.9523\n","Epoch 139/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2717 - auc: 0.9740 - val_loss: 0.3503 - val_auc: 0.9533\n","Epoch 140/500\n","21/21 [==============================] - 3s 157ms/step - loss: 0.2719 - auc: 0.9740 - val_loss: 0.3545 - val_auc: 0.9515\n","Epoch 141/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2733 - auc: 0.9737 - val_loss: 0.3635 - val_auc: 0.9499\n","Epoch 142/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2730 - auc: 0.9738 - val_loss: 0.3536 - val_auc: 0.9508\n","Epoch 143/500\n","21/21 [==============================] - 2s 120ms/step - loss: 0.2729 - auc: 0.9739 - val_loss: 0.3544 - val_auc: 0.9529\n","Epoch 144/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2726 - auc: 0.9739 - val_loss: 0.3549 - val_auc: 0.9517\n","Epoch 145/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2724 - auc: 0.9740 - val_loss: 0.3562 - val_auc: 0.9526\n","Epoch 146/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2739 - auc: 0.9736 - val_loss: 0.3621 - val_auc: 0.9496\n","Epoch 147/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2750 - auc: 0.9733 - val_loss: 0.3551 - val_auc: 0.9514\n","Epoch 148/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2740 - auc: 0.9737 - val_loss: 0.3643 - val_auc: 0.9481\n","Epoch 149/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2738 - auc: 0.9738 - val_loss: 0.3570 - val_auc: 0.9508\n","Epoch 150/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2703 - auc: 0.9746 - val_loss: 0.3641 - val_auc: 0.9520\n","Epoch 151/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2736 - auc: 0.9738 - val_loss: 0.3591 - val_auc: 0.9501\n","Epoch 152/500\n","21/21 [==============================] - 3s 153ms/step - loss: 0.2752 - auc: 0.9734 - val_loss: 0.3637 - val_auc: 0.9534\n","Epoch 153/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2766 - auc: 0.9731 - val_loss: 0.3578 - val_auc: 0.9504\n","Epoch 154/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2734 - auc: 0.9740 - val_loss: 0.3518 - val_auc: 0.9525\n","Epoch 155/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.2698 - auc: 0.9748 - val_loss: 0.3769 - val_auc: 0.9464\n","Epoch 156/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2745 - auc: 0.9737 - val_loss: 0.3710 - val_auc: 0.9480\n","Epoch 157/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2744 - auc: 0.9738 - val_loss: 0.3636 - val_auc: 0.9513\n","Epoch 158/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2710 - auc: 0.9746 - val_loss: 0.3720 - val_auc: 0.9502\n","Epoch 159/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2739 - auc: 0.9738 - val_loss: 0.3657 - val_auc: 0.9478\n","Epoch 160/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2694 - auc: 0.9751 - val_loss: 0.3599 - val_auc: 0.9507\n","Epoch 161/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2698 - auc: 0.9750 - val_loss: 0.3567 - val_auc: 0.9517\n","Epoch 162/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2693 - auc: 0.9752 - val_loss: 0.3622 - val_auc: 0.9502\n","Epoch 163/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2705 - auc: 0.9749 - val_loss: 0.3653 - val_auc: 0.9511\n","Epoch 164/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2721 - auc: 0.9745 - val_loss: 0.3521 - val_auc: 0.9530\n","Epoch 165/500\n","21/21 [==============================] - 3s 156ms/step - loss: 0.2677 - auc: 0.9757 - val_loss: 0.3553 - val_auc: 0.9523\n","Epoch 166/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2691 - auc: 0.9753 - val_loss: 0.3706 - val_auc: 0.9484\n","Epoch 167/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2762 - auc: 0.9735 - val_loss: 0.3648 - val_auc: 0.9501\n","Epoch 168/500\n","21/21 [==============================] - 3s 122ms/step - loss: 0.2710 - auc: 0.9749 - val_loss: 0.3677 - val_auc: 0.9497\n","Epoch 169/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2696 - auc: 0.9752 - val_loss: 0.3645 - val_auc: 0.9522\n","Epoch 170/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2708 - auc: 0.9750 - val_loss: 0.3629 - val_auc: 0.9518\n","Epoch 171/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2709 - auc: 0.9751 - val_loss: 0.3605 - val_auc: 0.9516\n","Epoch 172/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2689 - auc: 0.9755 - val_loss: 0.3702 - val_auc: 0.9502\n","Epoch 173/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2688 - auc: 0.9755 - val_loss: 0.3606 - val_auc: 0.9518\n","Epoch 174/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2698 - auc: 0.9753 - val_loss: 0.3648 - val_auc: 0.9497\n","Epoch 175/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2672 - auc: 0.9760 - val_loss: 0.3746 - val_auc: 0.9512\n","Epoch 176/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2694 - auc: 0.9755 - val_loss: 0.3881 - val_auc: 0.9495\n","Epoch 177/500\n","21/21 [==============================] - 3s 155ms/step - loss: 0.2717 - auc: 0.9749 - val_loss: 0.3616 - val_auc: 0.9521\n","Epoch 178/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.2726 - auc: 0.9747 - val_loss: 0.3660 - val_auc: 0.9494\n","Epoch 179/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2651 - auc: 0.9766 - val_loss: 0.3660 - val_auc: 0.9494\n","Epoch 180/500\n","21/21 [==============================] - 3s 125ms/step - loss: 0.2647 - auc: 0.9767 - val_loss: 0.3600 - val_auc: 0.9514\n","Epoch 181/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2670 - auc: 0.9762 - val_loss: 0.3589 - val_auc: 0.9520\n","Epoch 182/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2643 - auc: 0.9768 - val_loss: 0.3670 - val_auc: 0.9499\n","Epoch 183/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2655 - auc: 0.9766 - val_loss: 0.3655 - val_auc: 0.9499\n","Epoch 184/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2656 - auc: 0.9766 - val_loss: 0.3753 - val_auc: 0.9496\n","Epoch 185/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2717 - auc: 0.9751 - val_loss: 0.3677 - val_auc: 0.9495\n","Epoch 186/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2671 - auc: 0.9762 - val_loss: 0.3673 - val_auc: 0.9497\n","Epoch 187/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2656 - auc: 0.9766 - val_loss: 0.3713 - val_auc: 0.9491\n","Epoch 188/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2757 - auc: 0.9741 - val_loss: 0.3546 - val_auc: 0.9527\n","Epoch 189/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2678 - auc: 0.9761 - val_loss: 0.3632 - val_auc: 0.9522\n","Epoch 190/500\n","21/21 [==============================] - 3s 156ms/step - loss: 0.2641 - auc: 0.9770 - val_loss: 0.3616 - val_auc: 0.9524\n","Epoch 191/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2618 - auc: 0.9775 - val_loss: 0.3641 - val_auc: 0.9504\n","Epoch 192/500\n","21/21 [==============================] - 3s 123ms/step - loss: 0.2639 - auc: 0.9771 - val_loss: 0.3830 - val_auc: 0.9487\n","Epoch 193/500\n","21/21 [==============================] - 2s 120ms/step - loss: 0.2675 - auc: 0.9763 - val_loss: 0.3762 - val_auc: 0.9487\n","Epoch 194/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2639 - auc: 0.9771 - val_loss: 0.3611 - val_auc: 0.9521\n","Epoch 195/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2664 - auc: 0.9766 - val_loss: 0.3735 - val_auc: 0.9493\n","Epoch 196/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2655 - auc: 0.9768 - val_loss: 0.3652 - val_auc: 0.9507\n","Epoch 197/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2633 - auc: 0.9773 - val_loss: 0.3701 - val_auc: 0.9500\n","Epoch 198/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2682 - auc: 0.9762 - val_loss: 0.3736 - val_auc: 0.9477\n","Epoch 199/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2670 - auc: 0.9765 - val_loss: 0.3656 - val_auc: 0.9506\n","Epoch 200/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2640 - auc: 0.9772 - val_loss: 0.3665 - val_auc: 0.9499\n","Epoch 201/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2641 - auc: 0.9772 - val_loss: 0.3692 - val_auc: 0.9495\n","Epoch 202/500\n","21/21 [==============================] - 3s 158ms/step - loss: 0.2610 - auc: 0.9780 - val_loss: 0.3784 - val_auc: 0.9469\n","Epoch 203/500\n","21/21 [==============================] - 2s 118ms/step - loss: 0.2623 - auc: 0.9777 - val_loss: 0.3704 - val_auc: 0.9509\n","Epoch 204/500\n","21/21 [==============================] - 3s 126ms/step - loss: 0.2629 - auc: 0.9776 - val_loss: 0.3730 - val_auc: 0.9495\n","Epoch 205/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.2635 - auc: 0.9775 - val_loss: 0.3728 - val_auc: 0.9483\n","Epoch 206/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.2672 - auc: 0.9766 - val_loss: 0.3903 - val_auc: 0.9476\n","Epoch 207/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2676 - auc: 0.9765 - val_loss: 0.3657 - val_auc: 0.9501\n","Epoch 208/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2613 - auc: 0.9780 - val_loss: 0.3730 - val_auc: 0.9508\n","Epoch 209/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2635 - auc: 0.9775 - val_loss: 0.3813 - val_auc: 0.9488\n","Epoch 210/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2670 - auc: 0.9766 - val_loss: 0.3809 - val_auc: 0.9488\n","Epoch 211/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2634 - auc: 0.9775 - val_loss: 0.3700 - val_auc: 0.9507\n","Epoch 212/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2609 - auc: 0.9783 - val_loss: 0.3773 - val_auc: 0.9488\n","Epoch 213/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2656 - auc: 0.9771 - val_loss: 0.3714 - val_auc: 0.9516\n","Epoch 214/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2630 - auc: 0.9778 - val_loss: 0.3705 - val_auc: 0.9497\n","Epoch 215/500\n","21/21 [==============================] - 3s 139ms/step - loss: 0.2623 - auc: 0.9779 - val_loss: 0.3737 - val_auc: 0.9492\n","Epoch 216/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2616 - auc: 0.9781 - val_loss: 0.3790 - val_auc: 0.9492\n","Epoch 217/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.2625 - auc: 0.9779 - val_loss: 0.3807 - val_auc: 0.9471\n","Epoch 218/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2644 - auc: 0.9775 - val_loss: 0.3717 - val_auc: 0.9504\n","Epoch 219/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2595 - auc: 0.9786 - val_loss: 0.3773 - val_auc: 0.9500\n","Epoch 220/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2606 - auc: 0.9785 - val_loss: 0.3729 - val_auc: 0.9506\n","Epoch 221/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2577 - auc: 0.9791 - val_loss: 0.3821 - val_auc: 0.9458\n","Epoch 222/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2606 - auc: 0.9785 - val_loss: 0.3793 - val_auc: 0.9477\n","Epoch 223/500\n","21/21 [==============================] - 2s 117ms/step - loss: 0.2628 - auc: 0.9780 - val_loss: 0.3840 - val_auc: 0.9477\n","Epoch 224/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2612 - auc: 0.9783 - val_loss: 0.3730 - val_auc: 0.9505\n","Epoch 225/500\n","21/21 [==============================] - 2s 114ms/step - loss: 0.2602 - auc: 0.9787 - val_loss: 0.3766 - val_auc: 0.9495\n","Epoch 226/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2601 - auc: 0.9786 - val_loss: 0.3890 - val_auc: 0.9473\n","Epoch 227/500\n","21/21 [==============================] - 3s 157ms/step - loss: 0.2674 - auc: 0.9769 - val_loss: 0.3743 - val_auc: 0.9502\n","Epoch 228/500\n","21/21 [==============================] - 3s 123ms/step - loss: 0.2628 - auc: 0.9780 - val_loss: 0.3722 - val_auc: 0.9502\n","Epoch 229/500\n","21/21 [==============================] - 3s 128ms/step - loss: 0.2636 - auc: 0.9779 - val_loss: 0.3773 - val_auc: 0.9485\n","Epoch 230/500\n","21/21 [==============================] - 2s 119ms/step - loss: 0.2610 - auc: 0.9785 - val_loss: 0.3781 - val_auc: 0.9482\n","Epoch 231/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2605 - auc: 0.9787 - val_loss: 0.3845 - val_auc: 0.9480\n","Epoch 232/500\n","21/21 [==============================] - 3s 120ms/step - loss: 0.2567 - auc: 0.9795 - val_loss: 0.3785 - val_auc: 0.9487\n","Epoch 233/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2621 - auc: 0.9783 - val_loss: 0.3719 - val_auc: 0.9503\n","Epoch 234/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2570 - auc: 0.9796 - val_loss: 0.3751 - val_auc: 0.9501\n","Epoch 235/500\n","21/21 [==============================] - 2s 115ms/step - loss: 0.2550 - auc: 0.9801 - val_loss: 0.3828 - val_auc: 0.9486\n","Epoch 236/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2572 - auc: 0.9796 - val_loss: 0.3859 - val_auc: 0.9474\n","Epoch 237/500\n","21/21 [==============================] - 2s 116ms/step - loss: 0.2551 - auc: 0.9800 - val_loss: 0.4030 - val_auc: 0.9464\n"]}],"source":["df_test_final = load_raw_data('test')\n","\n","X_train = preprocessor.fit_transform(df_train)\n","X_val = preprocessor.transform(df_val)\n","X_test_final = preprocessor.transform(df_test_final)\n","\n","model.fit(X_train, y_train, \n","          epochs=500, \n","          batch_size=1024,\n","          callbacks=callbacks,\n","          validation_data=(X_val, y_val)\n","         )\n","y_pred = model.predict(X_test_final)\n","submit(y_pred)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":4637.345943,"end_time":"2022-09-18T07:28:48.169705","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-09-18T06:11:30.823762","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}