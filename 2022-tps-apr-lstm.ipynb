{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"input_path = '../input/tabular-playground-series-apr-2022/'\noutput_path = './'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-16T09:08:01.668814Z","iopub.execute_input":"2022-09-16T09:08:01.669203Z","iopub.status.idle":"2022-09-16T09:08:01.698436Z","shell.execute_reply.started":"2022-09-16T09:08:01.669125Z","shell.execute_reply":"2022-09-16T09:08:01.697659Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\ndef load_raw_data(train_or_test='train'):\n    file_name = f'{input_path}/{train_or_test}.csv'\n    df = pd.read_csv(file_name)\n    return df\n\ndef load_label(train_or_test='train'):\n    file_name = input_path + ('train_labels.csv' if train_or_test=='train' else 'sample_submission.csv')\n    df = pd.read_csv(file_name)\n    return df['state'].values\n\ndef competition_metric(y_true, y_score):\n    return roc_auc_score(y_true, y_score)\n\ndef evaluate(model, X, y):\n    return competition_metric(y, model.predict_proba(X)[:, 1])\n\ndef submit(arr):\n    df = pd.read_csv(f'{input_path}/sample_submission.csv')\n    df['state'] = arr\n    df.to_csv(f'{output_path}/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:08:01.700331Z","iopub.execute_input":"2022-09-16T09:08:01.700771Z","iopub.status.idle":"2022-09-16T09:08:02.803683Z","shell.execute_reply.started":"2022-09-16T09:08:01.700730Z","shell.execute_reply":"2022-09-16T09:08:02.802555Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass RNNThickModel(keras.Model):\n    def __init__(self):\n        super(RNNThickModel, self).__init__()\n        self.fns = [\n            keras.layers.LSTM(\n                units=256, \n                kernel_regularizer=keras.regularizers.L2(2e-3),\n#                 recurrent_regularizer=keras.regularizers.L2(1e-5),\n#                 dropout=0.05,\n#                 recurrent_dropout=0.01,\n                return_sequences=True\n            ),\n            keras.layers.LSTM(\n                units=128,\n                kernel_regularizer=keras.regularizers.L2(2e-3),\n#                 recurrent_regularizer=keras.regularizers.L2(1e-5),\n#                 dropout=0.05,\n#                 recurrent_dropout=0.01,\n            ),\n            keras.layers.Dense(units=32, activation='elu'),\n            keras.layers.Dense(units=1, activation='sigmoid')\n        ]\n    \n    def call(self, inputs):\n        outputs = inputs\n        for layer in self.fns:\n            outputs = layer(outputs)\n        return outputs\n    \n    def predict_proba(self, X):\n        return np.concatenate([1-self.predict(X), self.predict(X)], axis=1)\n\ndef random_sensor_swap(x, y, random_state=None):\n    rng = np.random.default_rng(random_state)\n    p_swap = 0.5\n    indices = rng.choice(np.arange(x.shape[0]), int(p_swap*x.shape[0]), replace=False)\n    x_aug, y_aug = x[indices], y[indices]\n    swap_codes = rng.integers(0, 13, (x_aug.shape[0], 2))\n    for i in range(x_aug.shape[0]):\n        a, b = swap_codes[i]\n        x_aug[i, :, [a, b]] = x_aug[i, :, [b, a]]\n    x = np.concatenate([x, x_aug], axis=0)\n    y = np.concatenate([y, y_aug], axis=0)\n    return x, y\n\ndef group_splitter(df, nfold=5, random_state=None):\n    subject_nums = df['subject'].unique()\n    rng = np.random.default_rng(random_state)\n    subject_to_setnum = rng.integers(0, nfold, subject_nums.shape[0])\n    for i in range(nfold):\n        val_subjects = subject_nums[subject_to_setnum == i]\n        mask_df_val = df['subject'].isin(val_subjects)\n        mask_y_val = mask_df_val.iloc[::60]\n        yield mask_df_val, mask_y_val\n\n\nclass DF2arr(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        return X.loc[:, 'sensor_00':'sensor_12'].values.reshape(-1, 60, 13)\n    \n    \nclass MyPreprocessor(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X = normalize(X)\n        return X\n    \ndef normalize(x):\n    x = x / (np.linalg.norm(x, axis=1, keepdims=True) + 1e-10)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:08:02.809697Z","iopub.execute_input":"2022-09-16T09:08:02.812424Z","iopub.status.idle":"2022-09-16T09:08:09.449172Z","shell.execute_reply.started":"2022-09-16T09:08:02.812381Z","shell.execute_reply":"2022-09-16T09:08:09.448253Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import classification_report\ncv_scores = []\n\ndf = load_raw_data('train')\nX = DF2arr().transform(df)\ny = load_label('train')\nsubj_nums = df['subject']\n\npreprocessor = make_pipeline(DF2arr(), MyPreprocessor())\n\nkeras.backend.clear_session()\ntf.random.set_seed(42)\n\ncallbacks = [\n    keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)\n]\nfor mask_df_val, mask_y_val in group_splitter(df, nfold=5, random_state=42):\n    df_train, df_val = df[~mask_df_val], df[mask_df_val]\n    y_train, y_val = y[~mask_y_val], y[mask_y_val]\n    for mask_df_v, mask_y_v in group_splitter(df_train, nfold=5, random_state=42):\n        df_t, df_v = df_train[~mask_df_v], df_train[mask_df_v]\n        y_t, y_v = y_train[~mask_y_v], y_train[mask_y_v]\n\n    X_t = preprocessor.fit_transform(df_t)\n    X_v = preprocessor.transform(df_v)\n    X_val = preprocessor.transform(df_val)\n\n    with tf.device('gpu:0'):\n        model = RNNThickModel()\n        model.compile(\n            loss='binary_crossentropy', \n            metrics=['AUC'],\n            optimizer=keras.optimizers.Adam(1e-3))\n        model.fit(\n            X_t, y_t, \n            batch_size=1024,\n            epochs=500, \n            callbacks=callbacks,\n            validation_data=(X_v, y_v),\n            verbose=0\n        )\n    print(evaluate(model, X_val, y_val))\n    print(classification_report(y_val, (model.predict(X_val) >= 0.5).astype(int), digits=4 ))\n    \n    cv_scores.append(evaluate(model, X_val, y_val))\nprint(f'5-fold CV score: {np.mean(cv_scores):.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:27:41.649851Z","iopub.execute_input":"2022-09-16T09:27:41.650333Z","iopub.status.idle":"2022-09-16T09:54:38.732084Z","shell.execute_reply.started":"2022-09-16T09:27:41.650279Z","shell.execute_reply":"2022-09-16T09:54:38.731107Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"0.9550240858938919\n              precision    recall  f1-score   support\n\n           0     0.8668    0.9035    0.8848      2592\n           1     0.8979    0.8593    0.8782      2559\n\n    accuracy                         0.8816      5151\n   macro avg     0.8823    0.8814    0.8815      5151\nweighted avg     0.8822    0.8816    0.8815      5151\n\n0.9521588824661936\n              precision    recall  f1-score   support\n\n           0     0.8763    0.9075    0.8916      2412\n           1     0.8939    0.8587    0.8759      2187\n\n    accuracy                         0.8843      4599\n   macro avg     0.8851    0.8831    0.8838      4599\nweighted avg     0.8847    0.8843    0.8842      4599\n\n0.6153964112512665\n              precision    recall  f1-score   support\n\n           0     0.6738    0.3385    0.4506      2789\n           1     0.5992    0.8579    0.7056      3215\n\n    accuracy                         0.6166      6004\n   macro avg     0.6365    0.5982    0.5781      6004\nweighted avg     0.6338    0.6166    0.5871      6004\n\n0.9646432734632807\n              precision    recall  f1-score   support\n\n           0     0.9100    0.8830    0.8963      2564\n           1     0.8915    0.9167    0.9040      2690\n\n    accuracy                         0.9003      5254\n   macro avg     0.9008    0.8999    0.9001      5254\nweighted avg     0.9005    0.9003    0.9002      5254\n\n0.9554479590125721\n              precision    recall  f1-score   support\n\n           0     0.8774    0.9203    0.8983      2597\n           1     0.9074    0.8587    0.8824      2363\n\n    accuracy                         0.8909      4960\n   macro avg     0.8924    0.8895    0.8903      4960\nweighted avg     0.8917    0.8909    0.8907      4960\n\n5-fold CV score: 0.8885\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test_final = load_raw_data('test')\n\nX_train = preprocessor.fit_transform(df_train)\nX_val = preprocessor.transform(df_val)\nX_test_final = preprocessor.transform(df_test_final)\n\nwith tf.device('gpu:0'):\n    model.fit(X_train, y_train, \n              epochs=500, \n              batch_size=1024,\n              callbacks=callbacks,\n              validation_data=(X_val, y_val)\n             )\ny_pred = model.predict(X_test_final)\nsubmit(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:27:37.936842Z","iopub.status.idle":"2022-09-16T09:27:37.937381Z","shell.execute_reply.started":"2022-09-16T09:27:37.937145Z","shell.execute_reply":"2022-09-16T09:27:37.937168Z"},"trusted":true},"execution_count":null,"outputs":[]}]}