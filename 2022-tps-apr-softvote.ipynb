{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7434b94",
   "metadata": {
    "_cell_guid": "e9ca7ffd-04b4-4306-be89-47e9820808ff",
    "_uuid": "418a416b-3a53-4812-a723-fd867fcfa0ce",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-22T01:25:45.036163Z",
     "iopub.status.busy": "2022-09-22T01:25:45.035485Z",
     "iopub.status.idle": "2022-09-22T01:25:45.045180Z",
     "shell.execute_reply": "2022-09-22T01:25:45.044365Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.016378,
     "end_time": "2022-09-22T01:25:45.047443",
     "exception": false,
     "start_time": "2022-09-22T01:25:45.031065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_path = '../input/tabular-playground-series-apr-2022/'\n",
    "output_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440614c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-22T01:25:45.053485Z",
     "iopub.status.busy": "2022-09-22T01:25:45.052836Z",
     "iopub.status.idle": "2022-09-22T01:25:45.889649Z",
     "shell.execute_reply": "2022-09-22T01:25:45.888741Z"
    },
    "papermill": {
     "duration": 0.842133,
     "end_time": "2022-09-22T01:25:45.892009",
     "exception": false,
     "start_time": "2022-09-22T01:25:45.049876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def load_raw_data(train_or_test='train'):\n",
    "    file_name = f'{input_path}/{train_or_test}.csv'\n",
    "    df = pd.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "def load_label(train_or_test='train'):\n",
    "    file_name = input_path + ('train_labels.csv' if train_or_test=='train' else 'sample_submission.csv')\n",
    "    df = pd.read_csv(file_name)\n",
    "    return df['state'].values\n",
    "\n",
    "def competition_metric(y_true, y_score):\n",
    "    return roc_auc_score(y_true, y_score)\n",
    "\n",
    "def evaluate(model, X, y):\n",
    "    return competition_metric(y, model.predict_proba(X)[:, 1])\n",
    "\n",
    "def submit(arr):\n",
    "    df = pd.read_csv(f'{input_path}/sample_submission.csv')\n",
    "    df['state'] = arr\n",
    "    df.to_csv(f'{output_path}/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa9f6e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-22T01:25:45.898666Z",
     "iopub.status.busy": "2022-09-22T01:25:45.897936Z",
     "iopub.status.idle": "2022-09-22T01:25:50.897882Z",
     "shell.execute_reply": "2022-09-22T01:25:50.896928Z"
    },
    "papermill": {
     "duration": 5.005862,
     "end_time": "2022-09-22T01:25:50.900267",
     "exception": false,
     "start_time": "2022-09-22T01:25:45.894405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ResNetModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.fns = [\n",
    "            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)), \n",
    "            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n",
    "            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n",
    "            keras.layers.AveragePooling1D(2),\n",
    "            \n",
    "            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n",
    "            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n",
    "            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n",
    "            keras.layers.AveragePooling1D(2),\n",
    "            \n",
    "            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n",
    "            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n",
    "            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n",
    "            keras.layers.AveragePooling1D(3),\n",
    "            \n",
    "            keras.layers.GlobalAveragePooling1D(),\n",
    "            keras.layers.Dense(1, activation='sigmoid')\n",
    "        ]\n",
    "        self.bns = [\n",
    "            keras.layers.BatchNormalization(), \n",
    "            keras.layers.BatchNormalization(), \n",
    "            \n",
    "            keras.layers.BatchNormalization(), \n",
    "            keras.layers.BatchNormalization(), \n",
    "            \n",
    "            keras.layers.BatchNormalization(), \n",
    "            keras.layers.BatchNormalization(), \n",
    "            \n",
    "            keras.layers.BatchNormalization(), \n",
    "            keras.layers.BatchNormalization(), \n",
    "        ]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        \n",
    "        outputs = self.fns[0](outputs)\n",
    "        res = outputs\n",
    "        res = self.fns[1](res)\n",
    "        res = self.fns[2](res)\n",
    "        outputs += res\n",
    "        outputs = self.fns[3](outputs)\n",
    "        \n",
    "        outputs = self.fns[4](outputs)\n",
    "        res = outputs\n",
    "        res = self.fns[5](res)\n",
    "        res = self.fns[6](res)\n",
    "        outputs += res\n",
    "        outputs = self.fns[7](outputs)\n",
    "        \n",
    "        outputs = self.fns[8](outputs)\n",
    "        res = outputs\n",
    "        res = self.fns[9](res)\n",
    "        res = self.fns[10](res)\n",
    "        outputs += res\n",
    "        outputs = self.fns[11](outputs)\n",
    "        \n",
    "        outputs = self.fns[-2](outputs)\n",
    "        outputs = self.fns[-1](outputs)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.concatenate([1-self.predict(X), self.predict(X)], axis=1)\n",
    "\n",
    "def random_sensor_swap(x, y, random_state=None):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    p_swap = 0.5\n",
    "    indices = rng.choice(np.arange(x.shape[0]), int(p_swap*x.shape[0]), replace=False)\n",
    "    x_aug, y_aug = x[indices], y[indices]\n",
    "    swap_codes = rng.integers(0, 13, (x_aug.shape[0], 2))\n",
    "    for i in range(x_aug.shape[0]):\n",
    "        a, b = swap_codes[i]\n",
    "        x_aug[i, :, [a, b]] = x_aug[i, :, [b, a]]\n",
    "    x = np.concatenate([x, x_aug], axis=0)\n",
    "    y = np.concatenate([y, y_aug], axis=0)\n",
    "    return x, y\n",
    "\n",
    "def group_splitter(df, nfold=5, random_state=None):\n",
    "    subject_nums = df['subject'].unique()\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    subject_to_setnum = rng.integers(0, nfold, subject_nums.shape[0])\n",
    "    for i in range(nfold):\n",
    "        val_subjects = subject_nums[subject_to_setnum == i]\n",
    "        mask_df_val = df['subject'].isin(val_subjects)\n",
    "        mask_y_val = mask_df_val.iloc[::60]\n",
    "        yield mask_df_val, mask_y_val\n",
    "\n",
    "        \n",
    "class MyDataAugmenter():\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        return X, y\n",
    "\n",
    "class DF2arr(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, 'sensor_00':'sensor_12'].values.reshape(-1, 60, 13)\n",
    "    \n",
    "    \n",
    "class MyPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = normalize(X)\n",
    "        return X\n",
    "    \n",
    "def normalize(x):\n",
    "    x = x / (np.linalg.norm(x, axis=1, keepdims=True) + 1e-10)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c951b72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-22T01:25:50.906460Z",
     "iopub.status.busy": "2022-09-22T01:25:50.905968Z",
     "iopub.status.idle": "2022-09-22T01:25:50.917393Z",
     "shell.execute_reply": "2022-09-22T01:25:50.916569Z"
    },
    "papermill": {
     "duration": 0.016675,
     "end_time": "2022-09-22T01:25:50.919338",
     "exception": false,
     "start_time": "2022-09-22T01:25:50.902663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class RNNThickModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(RNNThickModel, self).__init__()\n",
    "        self.fns = [\n",
    "            keras.layers.LSTM(\n",
    "                units=256, \n",
    "                kernel_regularizer=keras.regularizers.L2(2e-3),\n",
    "#                 recurrent_regularizer=keras.regularizers.L2(1e-5),\n",
    "#                 dropout=0.05,\n",
    "#                 recurrent_dropout=0.01,\n",
    "                return_sequences=True\n",
    "            ),\n",
    "            keras.layers.LSTM(\n",
    "                units=128,\n",
    "                kernel_regularizer=keras.regularizers.L2(2e-3),\n",
    "#                 recurrent_regularizer=keras.regularizers.L2(1e-5),\n",
    "#                 dropout=0.05,\n",
    "#                 recurrent_dropout=0.01,\n",
    "            ),\n",
    "            keras.layers.Dense(units=32, activation='elu'),\n",
    "            keras.layers.Dense(units=1, activation='sigmoid')\n",
    "        ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        outputs = inputs\n",
    "        for layer in self.fns:\n",
    "            outputs = layer(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.concatenate([1-self.predict(X), self.predict(X)], axis=1)\n",
    "\n",
    "    \n",
    "class MySoftVoter():\n",
    "    def __init__(self, models, weights=None):\n",
    "        self.models = models\n",
    "        if weights is None:\n",
    "            weights = np.ones((len(models), ))\n",
    "        weights /= np.sum(weights)\n",
    "        self.weights = weights\n",
    "    \n",
    "    def predict(self, X):\n",
    "        result = np.zeros((X.shape[0], ), dtype=X.dtype)\n",
    "        for model, weight in zip(self.models, self.weights):\n",
    "            add = model.predict(X)\n",
    "            if len(add.shape) > 1:\n",
    "                add = add[:, 0]\n",
    "            result += add * weight\n",
    "        return result\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.stack([1-self.predict(X), self.predict(X)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3dc341b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-22T01:25:50.925251Z",
     "iopub.status.busy": "2022-09-22T01:25:50.924616Z",
     "iopub.status.idle": "2022-09-22T04:16:19.070417Z",
     "shell.execute_reply": "2022-09-22T04:16:19.069210Z"
    },
    "papermill": {
     "duration": 10228.151786,
     "end_time": "2022-09-22T04:16:19.073254",
     "exception": false,
     "start_time": "2022-09-22T01:25:50.921468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 01:26:00.795202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-22 01:26:00.915799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-22 01:26:00.916866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-22 01:26:00.919476: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-22 01:26:00.923569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-22 01:26:00.924549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-22 01:26:00.925452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-22 01:26:03.085544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-22 01:26:03.086370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-22 01:26:03.087066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-22 01:26:03.087654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-09-22 01:26:03.787151: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-09-22 01:26:07.270816: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2802 - auc: 0.9632\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3220 - auc: 0.9484\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3798 - auc: 0.9250\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2886 - auc: 0.9599\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.2965 - auc: 0.9576\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.3329 - auc: 0.9614\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.3584 - auc: 0.9469\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.3187 - auc: 0.9638\n",
      "161/161 [==============================] - 1s 5ms/step - loss: 0.3560 - auc: 0.9493\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.3087 - auc: 0.9656\n",
      "0.9745435198452328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9349    0.9035    0.9190      2592\n",
      "           1     0.9055    0.9363    0.9207      2559\n",
      "\n",
      "    accuracy                         0.9198      5151\n",
      "   macro avg     0.9202    0.9199    0.9198      5151\n",
      "weighted avg     0.9203    0.9198    0.9198      5151\n",
      "\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.3636 - auc: 0.9366\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.3506 - auc: 0.9448\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.3602 - auc: 0.9354\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.3574 - auc: 0.9370\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.3276 - auc: 0.9536\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.3345 - auc: 0.9602\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.3196 - auc: 0.9610\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.4070 - auc: 0.9384\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.3627 - auc: 0.9453\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.4144 - auc: 0.9394\n",
      "0.9657345038259397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9116    0.9104    0.9110      2412\n",
      "           1     0.9014    0.9026    0.9020      2187\n",
      "\n",
      "    accuracy                         0.9067      4599\n",
      "   macro avg     0.9065    0.9065    0.9065      4599\n",
      "weighted avg     0.9067    0.9067    0.9067      4599\n",
      "\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.3104 - auc: 0.9558\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6653 - auc: 0.6182\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.3225 - auc: 0.9519\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.6446 - auc: 0.6916\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.3199 - auc: 0.9521\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.3264 - auc: 0.9607\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.3347 - auc: 0.9576\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.4110 - auc: 0.9431\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.3149 - auc: 0.9629\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.3351 - auc: 0.9558\n",
      "0.969826027266639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8990    0.9064    0.9027      2789\n",
      "           1     0.9182    0.9117    0.9149      3215\n",
      "\n",
      "    accuracy                         0.9092      6004\n",
      "   macro avg     0.9086    0.9090    0.9088      6004\n",
      "weighted avg     0.9093    0.9092    0.9093      6004\n",
      "\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 0.3031 - auc: 0.9564\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 0.2700 - auc: 0.9656\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 0.6850 - auc: 0.5681\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 0.3024 - auc: 0.9571\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 0.2978 - auc: 0.9587\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.3158 - auc: 0.9617\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.3073 - auc: 0.9649\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.3162 - auc: 0.9625\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.3280 - auc: 0.9619\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 0.3251 - auc: 0.9623\n",
      "0.9748686415858122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9195    0.9091    0.9143      2564\n",
      "           1     0.9143    0.9242    0.9192      2690\n",
      "\n",
      "    accuracy                         0.9168      5254\n",
      "   macro avg     0.9169    0.9166    0.9168      5254\n",
      "weighted avg     0.9169    0.9168    0.9168      5254\n",
      "\n",
      "155/155 [==============================] - 2s 5ms/step - loss: 0.6570 - auc: 0.6010\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.6691 - auc: 0.5953\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.6703 - auc: 0.6212\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3087 - auc: 0.9541\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.3429 - auc: 0.9396\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3507 - auc: 0.9509\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3507 - auc: 0.9501\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3395 - auc: 0.9569\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3267 - auc: 0.9592\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3459 - auc: 0.9568\n",
      "0.9707900534993419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9262    0.9034    0.9146      2597\n",
      "           1     0.8966    0.9209    0.9086      2363\n",
      "\n",
      "    accuracy                         0.9117      4960\n",
      "   macro avg     0.9114    0.9121    0.9116      4960\n",
      "weighted avg     0.9121    0.9117    0.9117      4960\n",
      "\n",
      "5-fold CV score: 0.9712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "cv_scores = []\n",
    "\n",
    "df = load_raw_data('train')\n",
    "y = load_label('train')\n",
    "X = DF2arr().transform(df)\n",
    "subj_nums = df['subject']\n",
    "\n",
    "preprocessor = make_pipeline(DF2arr(), MyPreprocessor())\n",
    "\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)\n",
    "]\n",
    "for mask_df_val, mask_y_val in group_splitter(df, nfold=5, random_state=42):\n",
    "    df_train, df_val = df[~mask_df_val], df[mask_df_val]\n",
    "    y_train, y_val = y[~mask_y_val], y[mask_y_val]\n",
    "    for mask_df_v, mask_y_v in group_splitter(df_train, nfold=5, random_state=42):\n",
    "        df_t, df_v = df_train[~mask_df_v], df_train[mask_df_v]\n",
    "        y_t, y_v = y_train[~mask_y_v], y_train[mask_y_v]\n",
    "\n",
    "    X_t = preprocessor.fit_transform(df_t)\n",
    "    X_v = preprocessor.transform(df_v)\n",
    "    X_val = preprocessor.transform(df_val)\n",
    "\n",
    "    models = [RNNThickModel() for _ in range(5)] + [ResNetModel() for _ in range(5)]\n",
    "    weights = []\n",
    "    for model in models:\n",
    "        with tf.device('gpu:0'):\n",
    "            model.compile(\n",
    "                loss='binary_crossentropy', \n",
    "                metrics=['AUC'],\n",
    "                optimizer=keras.optimizers.Adam(1e-3))\n",
    "            model.fit(\n",
    "                X_t, y_t, \n",
    "                batch_size=1024,\n",
    "                epochs=500, \n",
    "                callbacks=callbacks,\n",
    "                validation_data=(X_v, y_v),\n",
    "                verbose=0\n",
    "            )\n",
    "            weights.append( model.evaluate(X_val, y_val)[-1] - 0.5 )\n",
    "\n",
    "    model = MySoftVoter(models, weights)\n",
    "    print(evaluate(model, X_val, y_val))\n",
    "    print(classification_report(y_val, (model.predict(X_val) >= 0.5).astype(int), digits=4 ))\n",
    "    \n",
    "    cv_scores.append(evaluate(model, X_val, y_val))\n",
    "print(f'5-fold CV score: {np.mean(cv_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cac1e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-22T04:16:19.157270Z",
     "iopub.status.busy": "2022-09-22T04:16:19.156399Z",
     "iopub.status.idle": "2022-09-22T04:57:36.182639Z",
     "shell.execute_reply": "2022-09-22T04:57:36.181695Z"
    },
    "papermill": {
     "duration": 2477.070824,
     "end_time": "2022-09-22T04:57:36.185358",
     "exception": false,
     "start_time": "2022-09-22T04:16:19.114534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 2s 6ms/step - loss: 0.2872 - auc: 0.9597\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.2934 - auc: 0.9596\n",
      "155/155 [==============================] - 2s 8ms/step - loss: 0.6526 - auc: 0.6699\n",
      "155/155 [==============================] - 2s 6ms/step - loss: 0.2831 - auc: 0.9611\n",
      "155/155 [==============================] - 2s 6ms/step - loss: 0.2818 - auc: 0.9618\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3021 - auc: 0.9661\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.2987 - auc: 0.9661\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3060 - auc: 0.9647\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.2942 - auc: 0.9674\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.3091 - auc: 0.9647\n"
     ]
    }
   ],
   "source": [
    "df_test_final = load_raw_data('test')\n",
    "\n",
    "X_train = preprocessor.fit_transform(df_train)\n",
    "X_val = preprocessor.transform(df_val)\n",
    "X_test_final = preprocessor.transform(df_test_final)\n",
    "\n",
    "models = [RNNThickModel() for _ in range(5)] + [ResNetModel() for _ in range(5)]\n",
    "weights = []\n",
    "for model in models:\n",
    "    with tf.device('gpu:0'):\n",
    "        model.compile(\n",
    "            loss='binary_crossentropy', \n",
    "            metrics=['AUC'],\n",
    "            optimizer=keras.optimizers.Adam(1e-3))\n",
    "        model.fit(\n",
    "            X_train, y_train, \n",
    "            epochs=500, \n",
    "            batch_size=1024,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=0\n",
    "        )\n",
    "        weights.append( model.evaluate(X_val, y_val)[-1] - 0.5 )\n",
    "    \n",
    "model = MySoftVoter(models, weights)\n",
    "y_pred = model.predict(X_test_final)\n",
    "submit(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12722.565443,
   "end_time": "2022-09-22T04:57:40.182457",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-22T01:25:37.617014",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
