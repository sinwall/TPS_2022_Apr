{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# What did work\n\n- random multiplicative perturbation\n\n- revert every sensor but sensor_02\n\n- ensemble with different random seed\n\n# What did not work\n\n- revert every sensor (auc=0.5 ??????)\n\n- random dual cut&paste\n\n- random sensor swap","metadata":{}},{"cell_type":"code","source":"input_path = '../input/tabular-playground-series-apr-2022/'\noutput_path = './'","metadata":{"_uuid":"418a416b-3a53-4812-a723-fd867fcfa0ce","_cell_guid":"e9ca7ffd-04b4-4306-be89-47e9820808ff","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-23T07:14:25.183898Z","iopub.execute_input":"2022-09-23T07:14:25.184349Z","iopub.status.idle":"2022-09-23T07:14:25.211319Z","shell.execute_reply.started":"2022-09-23T07:14:25.184259Z","shell.execute_reply":"2022-09-23T07:14:25.210335Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\ndef load_raw_data(train_or_test='train'):\n    file_name = f'{input_path}/{train_or_test}.csv'\n    df = pd.read_csv(file_name)\n    return df\n\ndef load_label(train_or_test='train'):\n    file_name = input_path + ('train_labels.csv' if train_or_test=='train' else 'sample_submission.csv')\n    df = pd.read_csv(file_name)\n    return df['state'].values\n\ndef competition_metric(y_true, y_score):\n    return roc_auc_score(y_true, y_score)\n\ndef evaluate(model, X, y):\n    return competition_metric(y, model.predict_proba(X)[:, 1])\n\ndef submit(arr):\n    df = pd.read_csv(f'{input_path}/sample_submission.csv')\n    df['state'] = arr\n    df.to_csv(f'{output_path}/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T07:14:25.212834Z","iopub.execute_input":"2022-09-23T07:14:25.213911Z","iopub.status.idle":"2022-09-23T07:14:26.247967Z","shell.execute_reply.started":"2022-09-23T07:14:25.213862Z","shell.execute_reply":"2022-09-23T07:14:26.246673Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass ResNetModel(keras.Model):\n    def __init__(self):\n        super(ResNetModel, self).__init__()\n        self.fns = [\n            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)), \n            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.AveragePooling1D(2),\n            \n            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.AveragePooling1D(2),\n            \n            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.AveragePooling1D(3),\n            \n            keras.layers.GlobalAveragePooling1D(),\n            keras.layers.Dense(1, activation='sigmoid')\n        ]\n        self.bns = [\n            keras.layers.BatchNormalization(), \n            keras.layers.BatchNormalization(), \n            \n            keras.layers.BatchNormalization(), \n            keras.layers.BatchNormalization(), \n            \n            keras.layers.BatchNormalization(), \n            keras.layers.BatchNormalization(), \n            \n            keras.layers.BatchNormalization(), \n            keras.layers.BatchNormalization(), \n        ]\n        \n    def call(self, inputs):\n        outputs = inputs\n        \n        outputs = self.fns[0](outputs)\n        res = outputs\n        res = self.fns[1](res)\n        res = self.fns[2](res)\n        outputs += res\n        outputs = self.fns[3](outputs)\n        \n        outputs = self.fns[4](outputs)\n        res = outputs\n        res = self.fns[5](res)\n        res = self.fns[6](res)\n        outputs += res\n        outputs = self.fns[7](outputs)\n        \n        outputs = self.fns[8](outputs)\n        res = outputs\n        res = self.fns[9](res)\n        res = self.fns[10](res)\n        outputs += res\n        outputs = self.fns[11](outputs)\n        \n        outputs = self.fns[-2](outputs)\n        outputs = self.fns[-1](outputs)\n        \n        return outputs\n    \n    def predict_proba(self, X):\n        return np.concatenate([1-self.predict(X), self.predict(X)], axis=1)\n\ndef group_splitter(df, nfold=5, random_state=None):\n    subject_nums = df['subject'].unique()\n    rng = np.random.default_rng(random_state)\n    subject_to_setnum = rng.integers(0, nfold, subject_nums.shape[0])\n    for i in range(nfold):\n        val_subjects = subject_nums[subject_to_setnum == i]\n        mask_df_val = df['subject'].isin(val_subjects)\n        mask_y_val = mask_df_val.iloc[::60]\n        yield mask_df_val, mask_y_val\n\n        \nclass MyDataAugmenter():\n    def __init__(self, random_state=None):\n        self.random_state = random_state\n        \n    def fit(self, X, y):\n        return self\n    \n    def transform(self, X, y):\n        rng = np.random.default_rng(self.random_state)\n        X_aug, y_aug = X.copy(), y.copy()\n        X_aug.iloc[:, 3:16] = -X_aug.iloc[:, 15:2:-1]\n        X = pd.concat([X, X_aug], axis=0, ignore_index=True)\n        y = np.concatenate([y, y_aug], axis=0)\n        return X, y\n\nclass DF2arr(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        return X.loc[:, 'sensor_00':'sensor_12'].values.reshape(-1, 60, 13)\n    \n    \nclass MyPreprocessor(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X = normalize(X)\n        return X\n    \ndef normalize(x):\n    x = x / (np.linalg.norm(x, axis=1, keepdims=True) + 1e-10)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-09-23T07:14:26.251251Z","iopub.execute_input":"2022-09-23T07:14:26.251901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass RNNThickModel(keras.Model):\n    def __init__(self):\n        super(RNNThickModel, self).__init__()\n        self.fns = [\n            keras.layers.LSTM(\n                units=256, \n                kernel_regularizer=keras.regularizers.L2(2e-3),\n#                 recurrent_regularizer=keras.regularizers.L2(1e-5),\n#                 dropout=0.05,\n#                 recurrent_dropout=0.01,\n                return_sequences=True\n            ),\n            keras.layers.LSTM(\n                units=128,\n                kernel_regularizer=keras.regularizers.L2(2e-3),\n#                 recurrent_regularizer=keras.regularizers.L2(1e-5),\n#                 dropout=0.05,\n#                 recurrent_dropout=0.01,\n            ),\n            keras.layers.Dense(units=32, activation='elu'),\n            keras.layers.Dense(units=1, activation='sigmoid')\n        ]\n    \n    def call(self, inputs):\n        outputs = inputs\n        for layer in self.fns:\n            outputs = layer(outputs)\n        return outputs\n    \n    def predict_proba(self, X):\n        return np.concatenate([1-self.predict(X), self.predict(X)], axis=1)\n\n    \nclass MySoftVoter():\n    def __init__(self, models, weights=None):\n        self.models = models\n        if weights is None:\n            weights = np.ones((len(models), ))\n        weights /= np.sum(weights)\n        self.weights = weights\n    \n    def predict(self, X):\n        result = np.zeros((X.shape[0], ), dtype=X.dtype)\n        for model, weight in zip(self.models, self.weights):\n            add = model.predict(X)\n            if len(add.shape) > 1:\n                add = add[:, 0]\n            result += add * weight\n        return result\n    \n    def predict_proba(self, X):\n        return np.stack([1-self.predict(X), self.predict(X)], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.metrics import classification_report\ncv_scores = []\n\ndf = load_raw_data('train')\ny = load_label('train')\ndf, y = MyDataAugmenter(random_state=42).transform(df, y)\n\nX = DF2arr().transform(df)\nsubj_nums = df['subject']\n\npreprocessor = make_pipeline(DF2arr(), MyPreprocessor())\n\nkeras.backend.clear_session()\ntf.random.set_seed(42)\n\ncallbacks = [\n    keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)\n]\nfor mask_df_val, mask_y_val in group_splitter(df, nfold=5, random_state=42):\n    df_train, df_val = df[~mask_df_val], df[mask_df_val]\n    y_train, y_val = y[~mask_y_val], y[mask_y_val]\n    for mask_df_v, mask_y_v in group_splitter(df_train, nfold=5, random_state=42):\n        df_t, df_v = df_train[~mask_df_v], df_train[mask_df_v]\n        y_t, y_v = y_train[~mask_y_v], y_train[mask_y_v]\n\n    X_t = preprocessor.fit_transform(df_t)\n    X_v = preprocessor.transform(df_v)\n    X_val = preprocessor.transform(df_val)\n\n    models = [RNNThickModel() for _ in range(3)] + [ResNetModel() for _ in range(3)]\n    weights = []\n    for model in models:\n        with tf.device('gpu:0'):\n            model.compile(\n                loss='binary_crossentropy', \n                metrics=['AUC'],\n                optimizer=keras.optimizers.Adam(1e-3))\n            model.fit(\n                X_t, y_t, \n                batch_size=1024,\n                epochs=500, \n                callbacks=callbacks,\n                validation_data=(X_v, y_v),\n                verbose=0\n            )\n            weights.append( model.evaluate(X_val, y_val)[-1] - 0.5 )\n\n    model = MySoftVoter(models, weights)\n    print(evaluate(model, X_val, y_val))\n    print(classification_report(y_val, (model.predict(X_val) >= 0.5).astype(int), digits=4 ))\n    \n    cv_scores.append(evaluate(model, X_val, y_val))\nprint(f'5-fold CV score: {np.mean(cv_scores):.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_final = load_raw_data('test')\n\nX_train = preprocessor.fit_transform(df_train)\nX_val = preprocessor.transform(df_val)\nX_test_final = preprocessor.transform(df_test_final)\n\nmodels = [RNNThickModel() for _ in range(3)] + [ResNetModel() for _ in range(3)]\nweights = []\nfor model in models:\n    with tf.device('gpu:0'):\n        model.compile(\n            loss='binary_crossentropy', \n            metrics=['AUC'],\n            optimizer=keras.optimizers.Adam(1e-3))\n        model.fit(\n            X_train, y_train, \n            epochs=500, \n            batch_size=1024,\n            callbacks=callbacks,\n            validation_data=(X_val, y_val),\n            verbose=0\n        )\n        weights.append( model.evaluate(X_val, y_val)[-1] - 0.5 )\n    \nmodel = MySoftVoter(models, weights)\ny_pred = model.predict(X_test_final)\nsubmit(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}