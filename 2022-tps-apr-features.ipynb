{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Non-NN models","metadata":{}},{"cell_type":"markdown","source":"We should study these notebooks:\n\nhttps://www.kaggle.com/code/jeroenvdd/tpsapr22-best-non-dl-model-tsflex-powershap?scriptVersionId=94240450\n\nhttps://www.kaggle.com/code/ambrosm/tpsapr22-best-model-without-nn","metadata":{}},{"cell_type":"code","source":"input_path = '../input/tabular-playground-series-apr-2022/'\noutput_path = './'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-16T04:44:55.992560Z","iopub.execute_input":"2022-09-16T04:44:55.993039Z","iopub.status.idle":"2022-09-16T04:44:56.021044Z","shell.execute_reply.started":"2022-09-16T04:44:55.992948Z","shell.execute_reply":"2022-09-16T04:44:56.020229Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\ndef load_raw_data(train_or_test='train'):\n    file_name = f'{input_path}/{train_or_test}.csv'\n    df = pd.read_csv(file_name)\n    return df\n\ndef load_label(train_or_test='train'):\n    file_name = input_path + ('train_labels.csv' if train_or_test=='train' else 'sample_submission.csv')\n    df = pd.read_csv(file_name)\n    return df['state'].values\n\ndef competition_metric(y_true, y_score):\n    return roc_auc_score(y_true, y_score)\n\ndef evaluate(model, X, y):\n    return competition_metric(y, model.predict_proba(X)[:, 1])\n\ndef submit(arr):\n    df = pd.read_csv(f'{input_path}/sample_submission.csv')\n    df['state'] = arr\n    df.to_csv(f'{output_path}/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-16T04:44:56.022652Z","iopub.execute_input":"2022-09-16T04:44:56.023227Z","iopub.status.idle":"2022-09-16T04:44:57.213337Z","shell.execute_reply.started":"2022-09-16T04:44:56.023190Z","shell.execute_reply":"2022-09-16T04:44:57.212196Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import TransformerMixin, BaseEstimator\nfrom scipy.stats import kurtosis\nfrom tsfresh.feature_extraction.extraction import extract_features\n\nclass ElementaryExtractor(BaseEstimator, TransformerMixin):\n    features_to_use = ['med_abs_val_00',\n        'max_abs_val_00',\n        'sum_abs_diff_00',\n        'l2_sum_00',\n        'l2_sum_diff_00',\n        'l2_sum_diff2_00',\n        'kurt_00',\n        'sm_00',\n        'kurt_diff_00',\n        'mean_01',\n        'med_abs_val_01',\n        'l2_sum_diff2_01',\n        'sm_01',\n        'iqr_diff_01',\n        'mean_02',\n        'med_abs_val_02',\n        'max_abs_val_02',\n        'med_abs_diff_02',\n        'max_abs_diff_02',\n        'l2_sum_diff_02',\n        'l2_sum_diff2_02',\n        'std_02',\n        'kurt_02',\n        'std_diff_02',\n        'iqr_diff_02',\n        'kurt_diff_02',\n        'med_abs_val_03',\n        'med_abs_diff_03',\n        'max_abs_diff_03',\n        'sum_abs_diff_03',\n        'sm_03',\n        'iqr_diff_03',\n        'mean_04',\n        'med_abs_val_04',\n        'max_abs_val_04',\n        'med_abs_diff_04',\n        'max_abs_diff_04',\n        'l2_sum_04',\n        'l2_sum_diff2_04',\n        'iqr_04',\n        'kurt_04',\n        'sm_04',\n        'kurt_diff_04',\n        'mean_05',\n        'med_abs_diff_05',\n        'sum_abs_diff_05',\n        'sm_05',\n        'mean_06',\n        'med_abs_val_06',\n        'med_abs_diff_06',\n        'max_abs_diff_06',\n        'l2_sum_diff2_06',\n        'kurt_06',\n        'iqr_diff_06',\n        'kurt_diff_06',\n        'med_abs_val_07',\n        'sum_abs_diff_07',\n        'l2_sum_07',\n        'l2_sum_diff_07',\n        'l2_sum_diff2_07',\n        'iqr_07',\n        'sm_07',\n        'iqr_diff_07',\n        'kurt_diff_07',\n        'max_abs_diff_08',\n        'sum_abs_diff_08',\n        'l2_sum_08',\n        'l2_sum_diff_08',\n        'l2_sum_diff2_08',\n        'iqr_08',\n        'kurt_08',\n        'iqr_diff_08',\n        'kurt_diff_08',\n        'mean_09',\n        'max_abs_diff_09',\n        'sum_abs_diff_09',\n        'l2_sum_09',\n        'l2_sum_diff2_09',\n        'sm_09',\n        'iqr_diff_09',\n        'kurt_diff_09',\n        'mean_10',\n        'med_abs_val_10',\n        'max_abs_diff_10',\n        'l2_sum_diff2_10',\n        'std_10',\n        'kurt_10',\n        'sm_10',\n        'std_diff_10',\n        'kurt_diff_10',\n        'mean_11',\n        'sum_abs_diff_11',\n        'l2_sum_diff_11',\n        'sm_11',\n        'iqr_diff_11',\n        'kurt_diff_11',\n        'max_abs_diff_12',\n        'sum_abs_diff_12',\n        'l2_sum_12',\n        'l2_sum_diff2_12',\n        'iqr_12',\n        'kurt_12',\n        'sm_12',\n        'kurt_diff_12',\n        'up_sum_02',\n        'up_max_02',\n        'up_mean_02',\n        'down_count_02']\n    \n    def fit(self, X):\n        return self\n    \n    def transform(self, X, y=None):\n        seq_no = X['sequence'].iloc[::60]\n        x = X.loc[:, 'sensor_00':'sensor_12'].values.reshape(-1, 60, 13)\n        features = dict()\n        for i in range(13):\n            channel = x[:, :, i]\n            # mean\n            features[f'mean_{i:0>2}'] = np.mean(channel, axis=1)\n            # median of absolute values\n            features[f'med_abs_val_{i:0>2}'] = np.median(np.abs(channel), axis=1)\n            # maximum of absolute values\n            features[f'max_abs_val_{i:0>2}'] = np.max(np.abs(channel), axis=1)\n            #median of absolute diff\n            features[f'med_abs_diff_{i:0>2}'] = np.median(np.abs(np.diff(channel, axis=1)), axis=1)\n            # maximum of absolute diff\n            features[f'max_abs_diff_{i:0>2}'] = np.max(np.abs(np.diff(channel, axis=1)), axis=1)\n            # absolute sum of difference\n            features[f'sum_abs_diff_{i:0>2}'] = np.sum(np.abs(np.diff(channel, axis=1)), axis=1)\n            # square sum\n            features[f'l2_sum_{i:0>2}'] = np.linalg.norm(channel, axis=1)\n            # square sum of difference\n            features[f'l2_sum_diff_{i:0>2}'] = np.linalg.norm(np.diff(channel, axis=1), axis=1)\n            # square sum of 2-diff\n            features[f'l2_sum_diff2_{i:0>2}'] = np.linalg.norm(np.diff(np.diff(channel, axis=1), axis=1), axis=1)\n            # standard deviation\n            features[f'std_{i:0>2}'] = np.std(channel, axis=1)\n            features[f'iqr_{i:0>2}'] = np.quantile(channel, 0.75, axis=1) - np.quantile(channel, 0.25, axis=1)\n            features[f'kurt_{i:0>2}'] = kurtosis(channel, axis=1)\n            features[f'sm_{i:0>2}'] = np.nan_to_num(features[f'std_{i:0>2}'] / np.abs(np.mean(channel, axis=1))).clip(-1e30, 1e30)\n\n            features[f'std_diff_{i:0>2}'] = np.std(np.diff(channel, axis=1), axis=1)\n            features[f'iqr_diff_{i:0>2}'] = np.quantile(np.diff(channel, axis=1), 0.75, axis=1) - np.quantile(np.diff(channel, axis=1), 0.25, axis=1)\n            features[f'kurt_diff_{i:0>2}'] = kurtosis(np.diff(channel, axis=1), axis=1)\n\n        sensor_02 = x[:, :, 2]\n        features[f'up_count_02'] = np.sum(np.diff(sensor_02, axis=1) >= 0, axis=1)\n        features[f'up_sum_02'] = np.sum(np.clip(np.diff(sensor_02, axis=1), 0, None), axis=1)\n        features[f'up_max_02'] = np.max(np.clip(np.diff(sensor_02, axis=1), 0, None), axis=1)\n        features[f'up_mean_02'] = np.nan_to_num(features[f'up_max_02'] / features[f'up_count_02'], posinf=40)\n\n        features[f'down_count_02'] = np.sum(np.diff(sensor_02, axis=1) < 0, axis=1)\n        features[f'down_sum_02'] = np.sum(np.clip(np.diff(sensor_02, axis=1), None, 0), axis=1)\n        features[f'down_min_02'] = np.sum(np.clip(np.diff(sensor_02, axis=1), None, 0), axis=1)\n        features[f'down_mean_02'] = np.nan_to_num(features[f'down_min_02'] / features[f'down_count_02'], neginf=-40)\n        \n        return pd.DataFrame(features, index=seq_no)[self.features_to_use]\n    \nclass TsfreshExtractor(BaseEstimator, TransformerMixin):\n    sensorwise_fcs = [{'agg_autocorrelation': [{'f_agg': 'var', 'maxlag': 40}],\n        'agg_linear_trend': [{'attr': 'stderr', 'chunk_len': 10, 'f_agg': 'max'}],\n        'ar_coefficient': [{'coeff': 0, 'k': 10},\n        {'coeff': 4, 'k': 10},\n        {'coeff': 6, 'k': 10}],\n        'augmented_dickey_fuller': [{'attr': 'usedlag'}],\n        'fft_coefficient': [{'coeff': 1, 'attr': 'imag'}],\n        'skewness': [{}],\n        'spkt_welch_density': [{'coeff': 2}]},\n        {'ar_coefficient': [{'coeff': 0, 'k': 10},\n        {'coeff': 1, 'k': 10},\n        {'coeff': 2, 'k': 10},\n        {'coeff': 3, 'k': 10},\n        {'coeff': 4, 'k': 10},\n        {'coeff': 5, 'k': 10},\n        {'coeff': 6, 'k': 10},\n        {'coeff': 7, 'k': 10},\n        {'coeff': 9, 'k': 10}],\n        'fft_aggregated': [{'aggtype': 'kurtosis'}],\n        'fft_coefficient': [{'coeff': 1, 'attr': 'imag'}],\n        'spkt_welch_density': [{'coeff': 2}],\n        'variation_coefficient': [{}]},\n        {'absolute_sum_of_changes': [{}],\n        'agg_linear_trend': [{'attr': 'intercept', 'chunk_len': 10, 'f_agg': 'var'},\n        {'attr': 'intercept', 'chunk_len': 50, 'f_agg': 'var'},\n        {'attr': 'stderr', 'chunk_len': 10, 'f_agg': 'var'},\n        {'attr': 'stderr', 'chunk_len': 5, 'f_agg': 'max'},\n        {'attr': 'stderr', 'chunk_len': 5, 'f_agg': 'var'}],\n        'change_quantiles': [{'ql': 0.0, 'qh': 0.4, 'isabs': True, 'f_agg': 'mean'},\n        {'ql': 0.0, 'qh': 1.0, 'isabs': False, 'f_agg': 'var'},\n        {'ql': 0.0, 'qh': 1.0, 'isabs': True, 'f_agg': 'var'},\n        {'ql': 0.2, 'qh': 0.6, 'isabs': False, 'f_agg': 'mean'},\n        {'ql': 0.2, 'qh': 0.6, 'isabs': True, 'f_agg': 'var'},\n        {'ql': 0.2, 'qh': 0.8, 'isabs': False, 'f_agg': 'mean'},\n        {'ql': 0.2, 'qh': 0.8, 'isabs': True, 'f_agg': 'mean'},\n        {'ql': 0.2, 'qh': 1.0, 'isabs': True, 'f_agg': 'mean'},\n        {'ql': 0.4, 'qh': 1.0, 'isabs': False, 'f_agg': 'mean'},\n        {'ql': 0.4, 'qh': 1.0, 'isabs': True, 'f_agg': 'mean'},\n        {'ql': 0.6, 'qh': 1.0, 'isabs': False, 'f_agg': 'mean'},\n        {'ql': 0.6, 'qh': 1.0, 'isabs': True, 'f_agg': 'var'},\n        {'ql': 0.8, 'qh': 1.0, 'isabs': False, 'f_agg': 'mean'}],\n        'cid_ce': [{'normalize': True}],\n        'cwt_coefficients': [{'widths': (2, 5, 10, 20), 'coeff': 1, 'w': 2}],\n        'fft_coefficient': [{'coeff': 1, 'attr': 'abs'}],\n        'matrix_profile': [{'threshold': 0.98, 'feature': 'min'}],\n        'partial_autocorrelation': [{'lag': 2}],\n        'permutation_entropy': [{'tau': 1, 'dimension': 4}],\n        'quantile': [{'q': 0.1}],\n        'ratio_value_number_to_time_series_length': [{}],\n        'spkt_welch_density': [{'coeff': 2}],\n        'standard_deviation': [{}],\n        'time_reversal_asymmetry_statistic': [{'lag': 1}]},\n        {'ar_coefficient': [{'coeff': 0, 'k': 10},\n        {'coeff': 4, 'k': 10},\n        {'coeff': 5, 'k': 10},\n        {'coeff': 6, 'k': 10},\n        {'coeff': 7, 'k': 10}],\n        'augmented_dickey_fuller': [{'attr': 'usedlag'}],\n        'fft_coefficient': [{'coeff': 1, 'attr': 'imag'}]},\n        {'agg_linear_trend': [{'attr': 'rvalue', 'chunk_len': 10, 'f_agg': 'min'},\n        {'attr': 'rvalue', 'chunk_len': 10, 'f_agg': 'var'},\n        {'attr': 'rvalue', 'chunk_len': 5, 'f_agg': 'max'},\n        {'attr': 'rvalue', 'chunk_len': 5, 'f_agg': 'var'},\n        {'attr': 'stderr', 'chunk_len': 10, 'f_agg': 'max'},\n        {'attr': 'stderr', 'chunk_len': 10, 'f_agg': 'min'}],\n        'ar_coefficient': [{'coeff': 0, 'k': 10},\n        {'coeff': 10, 'k': 10},\n        {'coeff': 2, 'k': 10}],\n        'augmented_dickey_fuller': [{'attr': 'usedlag'}],\n        'autocorrelation': [{'lag': 2}, {'lag': 6}],\n        'cid_ce': [{'normalize': True}],\n        'energy_ratio_by_chunks': [{'num_segments': 10, 'segment_focus': 1},\n        {'num_segments': 10, 'segment_focus': 3},\n        {'num_segments': 10, 'segment_focus': 5},\n        {'num_segments': 10, 'segment_focus': 6},\n        {'num_segments': 10, 'segment_focus': 7},\n        {'num_segments': 10, 'segment_focus': 9}],\n        'fft_aggregated': [{'aggtype': 'kurtosis'}, {'aggtype': 'skew'}],\n        'fft_coefficient': [{'coeff': 0, 'attr': 'abs'},\n        {'coeff': 0, 'attr': 'real'},\n        {'coeff': 3, 'attr': 'abs'},\n        {'coeff': 4, 'attr': 'abs'}],\n        'fourier_entropy': [{'bins': 100}],\n        'friedrich_coefficients': [{'coeff': 1, 'm': 3, 'r': 30},\n        {'coeff': 3, 'm': 3, 'r': 30}],\n        'index_mass_quantile': [{'q': 0.2}, {'q': 0.3}, {'q': 0.7}],\n        'kurtosis': [{}],\n        'large_standard_deviation': [{'r': 0.25}],\n        'number_peaks': [{'n': 10}, {'n': 5}],\n        'partial_autocorrelation': [{'lag': 4}, {'lag': 9}],\n        'permutation_entropy': [{'tau': 1, 'dimension': 5}],\n        'ratio_beyond_r_sigma': [{'r': 0.5}, {'r': 1}, {'r': 2}],\n        'skewness': [{}],\n        'spkt_welch_density': [{'coeff': 2}],\n        'time_reversal_asymmetry_statistic': [{'lag': 2}]},\n        {'ar_coefficient': [{'coeff': 0, 'k': 10},\n        {'coeff': 2, 'k': 10},\n        {'coeff': 4, 'k': 10},\n        {'coeff': 5, 'k': 10},\n        {'coeff': 6, 'k': 10}],\n        'cwt_coefficients': [{'widths': (2, 5, 10, 20), 'coeff': 10, 'w': 20}],\n        'fft_aggregated': [{'aggtype': 'kurtosis'}],\n        'fft_coefficient': [{'coeff': 0, 'attr': 'abs'},\n        {'coeff': 4, 'attr': 'abs'}],\n        'fourier_entropy': [{'bins': 100}],\n        'partial_autocorrelation': [{'lag': 9}],\n        'permutation_entropy': [{'tau': 1, 'dimension': 4}]},\n        {'agg_linear_trend': [{'attr': 'rvalue', 'chunk_len': 5, 'f_agg': 'max'}],\n        'ar_coefficient': [{'coeff': 0, 'k': 10},\n        {'coeff': 5, 'k': 10},\n        {'coeff': 6, 'k': 10}],\n        'fft_coefficient': [{'coeff': 1, 'attr': 'imag'}],\n        'spkt_welch_density': [{'coeff': 2}]},\n        {'agg_linear_trend': [{'attr': 'intercept', 'chunk_len': 5, 'f_agg': 'min'}],\n        'ar_coefficient': [{'coeff': 0, 'k': 10},\n        {'coeff': 1, 'k': 10},\n        {'coeff': 2, 'k': 10},\n        {'coeff': 4, 'k': 10},\n        {'coeff': 5, 'k': 10},\n        {'coeff': 6, 'k': 10}],\n        'augmented_dickey_fuller': [{'attr': 'usedlag'}],\n        'change_quantiles': [{'ql': 0.0, 'qh': 0.8, 'isabs': True, 'f_agg': 'mean'}],\n        'fft_coefficient': [{'coeff': 1, 'attr': 'abs'},\n        {'coeff': 1, 'attr': 'imag'}],\n        'number_crossing_m': [{'m': 0}],\n        'skewness': [{}],\n        'spkt_welch_density': [{'coeff': 2}]},\n        {'kurtosis': [{}]},\n        {'agg_linear_trend': [{'attr': 'intercept', 'chunk_len': 50, 'f_agg': 'var'}],\n        'ar_coefficient': [{'coeff': 0, 'k': 10},\n        {'coeff': 3, 'k': 10},\n        {'coeff': 4, 'k': 10},\n        {'coeff': 5, 'k': 10},\n        {'coeff': 6, 'k': 10},\n        {'coeff': 7, 'k': 10},\n        {'coeff': 8, 'k': 10}],\n        'augmented_dickey_fuller': [{'attr': 'usedlag'}],\n        'autocorrelation': [{'lag': 6}],\n        'fft_coefficient': [{'coeff': 1, 'attr': 'imag'}],\n        'quantile': [{'q': 0.9}],\n        'spkt_welch_density': [{'coeff': 2}]},\n        {'agg_autocorrelation': [{'f_agg': 'var', 'maxlag': 40}],\n        'agg_linear_trend': [{'attr': 'rvalue', 'chunk_len': 10, 'f_agg': 'var'}],\n        'ar_coefficient': [{'coeff': 0, 'k': 10}, {'coeff': 10, 'k': 10}],\n        'augmented_dickey_fuller': [{'attr': 'pvalue'}, {'attr': 'usedlag'}],\n        'autocorrelation': [{'lag': 1}, {'lag': 2}, {'lag': 5}, {'lag': 6}],\n        'change_quantiles': [{'ql': 0.2, 'qh': 0.8, 'isabs': False, 'f_agg': 'mean'},\n        {'ql': 0.2, 'qh': 0.8, 'isabs': True, 'f_agg': 'var'}],\n        'cid_ce': [{'normalize': True}],\n        'fft_aggregated': [{'aggtype': 'skew'}],\n        'fft_coefficient': [{'coeff': 4, 'attr': 'abs'}],\n        'fourier_entropy': [{'bins': 100}],\n        'friedrich_coefficients': [{'coeff': 3, 'm': 3, 'r': 30}],\n        'kurtosis': [{}],\n        'linear_trend': [{'attr': 'pvalue'}],\n        'partial_autocorrelation': [{'lag': 3}, {'lag': 4}, {'lag': 9}],\n        'permutation_entropy': [{'tau': 1, 'dimension': 4}],\n        'quantile': [{'q': 0.2}],\n        'spkt_welch_density': [{'coeff': 2}]},\n        {'ar_coefficient': [{'coeff': 0, 'k': 10},\n        {'coeff': 2, 'k': 10},\n        {'coeff': 4, 'k': 10},\n        {'coeff': 5, 'k': 10},\n        {'coeff': 6, 'k': 10},\n        {'coeff': 7, 'k': 10}],\n        'augmented_dickey_fuller': [{'attr': 'usedlag'}],\n        'fft_aggregated': [{'aggtype': 'kurtosis'}, {'aggtype': 'skew'}],\n        'fft_coefficient': [{'coeff': 1, 'attr': 'imag'}],\n        'spkt_welch_density': [{'coeff': 2}]},\n        {'agg_linear_trend': [{'attr': 'stderr', 'chunk_len': 10, 'f_agg': 'max'},\n        {'attr': 'stderr', 'chunk_len': 10, 'f_agg': 'min'}],\n        'ar_coefficient': [{'coeff': 0, 'k': 10},\n        {'coeff': 1, 'k': 10},\n        {'coeff': 10, 'k': 10},\n        {'coeff': 2, 'k': 10},\n        {'coeff': 6, 'k': 10}],\n        'augmented_dickey_fuller': [{'attr': 'usedlag'}],\n        'autocorrelation': [{'lag': 1}, {'lag': 2}],\n        'binned_entropy': [{'max_bins': 10}],\n        'change_quantiles': [{'ql': 0.0, 'qh': 0.2, 'isabs': False, 'f_agg': 'var'},\n        {'ql': 0.0, 'qh': 1.0, 'isabs': True, 'f_agg': 'var'},\n        {'ql': 0.4, 'qh': 0.6, 'isabs': True, 'f_agg': 'mean'}],\n        'fft_aggregated': [{'aggtype': 'kurtosis'}, {'aggtype': 'skew'}],\n        'fft_coefficient': [{'coeff': 0, 'attr': 'abs'},\n        {'coeff': 1, 'attr': 'abs'},\n        {'coeff': 22, 'attr': 'abs'},\n        {'coeff': 23, 'attr': 'abs'},\n        {'coeff': 24, 'attr': 'abs'},\n        {'coeff': 25, 'attr': 'abs'}],\n        'fourier_entropy': [{'bins': 100}],\n        'kurtosis': [{}],\n        'partial_autocorrelation': [{'lag': 2}, {'lag': 3}],\n        'ratio_beyond_r_sigma': [{'r': 2}],\n        'spkt_welch_density': [{'coeff': 2}]}]\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        df_tsf = []\n        for i in range(13):\n            sensor_name = f'sensor_{i:0>2}'\n            ts = X[['sequence', 'step', sensor_name]]\n            features = extract_features(\n                ts, \n                self.sensorwise_fcs[i],\n                column_id='sequence', \n                column_sort='step'\n            )\n            df_tsf.append( features )\n        df_tsf = pd.concat(df_tsf, axis=1)\n        return df_tsf\n    \n\ndef group_splitter(df, nfold=5, random_state=None):\n    subject_nums = df['subject'].unique()\n    rng = np.random.default_rng(random_state)\n    subject_to_setnum = rng.integers(0, nfold, subject_nums.shape[0])\n    for i in range(nfold):\n        val_subjects = subject_nums[subject_to_setnum == i]\n        mask_df_val = df['subject'].isin(val_subjects)\n        mask_y_val = mask_df_val.iloc[::60]\n        yield mask_df_val, mask_y_val","metadata":{"execution":{"iopub.status.busy":"2022-09-16T04:44:57.214966Z","iopub.execute_input":"2022-09-16T04:44:57.215270Z","iopub.status.idle":"2022-09-16T04:44:59.324883Z","shell.execute_reply.started":"2022-09-16T04:44:57.215242Z","shell.execute_reply":"2022-09-16T04:44:59.323874Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import TransformerMixin, BaseEstimator\n\nclass CorrExtractor(BaseEstimator, TransformerMixin):\n    #def __init__(self):\n        #self.features = {}\n        #self.list_df = []\n        #self.length = 0\n        #self.corrs = pd.DataFrame()\n    def fit(self, X):\n        return self\n\n    def transform(self, X, y=None):\n        def df_autocorr(df, lag=1, axis=0):\n            # Compute full-sample column-wise autocorrelation for a DataFrame.\n            return df.apply(lambda col: col.autocorr(lag), axis=axis)\n        features = {}\n        list_df = []\n        for n,g in X.groupby('sequence'):\n            list_df.append(g)\n        length = len(list_df)\n        corrs = pd.DataFrame()\n        for k in range(0,length):\n            features[k] = {}\n            for i in range(0,13):\n                features[k][f'autocorr_{i:0>2}'] = df_autocorr(list_df[k])[i+3]\n                features[k][f'autocorr_diff_{i:0>2}'] = df_autocorr(list_df[k].diff().drop(list_df[k].diff().index[[0]]))[i+3]\n                for j in range(0,13):\n                    if i>j:\n                        features[k][f'corr_{j:0>2}_{i:0>2}'] = list_df[k].loc[:, 'sensor_00':'sensor_12'].corr().iat[i,j]\n                    elif j>i:\n                        features[k][f'corr_diff_{i:0>2}_{j:0>2}'] = list_df[k].diff().drop(list_df[k].diff().index[[0]]).loc[:, 'sensor_00':'sensor_12'].corr().iat[i,j]\n            corrs = pd.concat([corrs, pd.DataFrame(features[k], index = [list_df[k].iloc[0,0]])], axis=0)\n        return corrs.replace(np.nan, 0)\n    \nimport numpy as np\nimport pandas as pd\nfrom sklearn.base import TransformerMixin, BaseEstimator\n! pip install pyts\nfrom pyts.transformation import BagOfPatterns as BOP\n\nclass MBOP(BaseEstimator, TransformerMixin):\n    \"\"\"Multivariate Bag of patterns.\n    Given multivariate time series , MBOP splits indidual time series, BOP-transform \n    them and gather them in one dataframe data frame. further note is documnet of BOP.\n    \n    BOP\n    This algorithm uses a sliding window to extract subsequences from the\n    time series and transforms each subsequence into a word using the\n    Piecewise Aggregate Approximation and the Symbolic Aggregate approXimation\n    algorithms. Thus it transforms each time series into a bag of words.\n    Then it derives the frequencies of each word for each time series.\n\n    Parameters of MBOP\n    ----------\n    \n    n_channels : non negative int (default = 13)\n        number of time series\n        \n    m_occur: positive float strictly under 1 (default = 0.01)\n        parameter for reduction of dimension of features.\n        ignores feature of pattern of trivial occurrence.\n        while normal BOP produces features every pattern,\n        MBOP will drop column with mean of occurence less than m_occur \n        i.e. patterns that appear less than (sample * m_occur)\n    \n    \n    \n    \n    window_size : int or float (default = 0.5)\n        Length of the sliding window. If float, it represents\n        a percentage of the size of each time series and must be\n        between 0 and 1.\n\n    word_size : int or float (default = 0.5)\n        Length of the words. If float, it represents\n        a percentage of the length of the sliding window and must be\n        between 0. and 1.\n\n    n_bins : int (default = 4)\n        The number of bins to produce. It must be between 2 and\n        ``min(window_size, 26)``.\n\n    strategy : 'uniform', 'quantile' or 'normal' (default = 'normal')\n        Strategy used to define the widths of the bins:\n\n        - 'uniform': All bins in each sample have identical widths\n        - 'quantile': All bins in each sample have the same number of points\n        - 'normal': Bin edges are quantiles from a standard normal distribution\n\n    numerosity_reduction : bool (default = True)\n        If True, delete sample-wise all but one occurence of back to back\n        identical occurences of the same words.\n\n    window_step : int or float (default = 1)\n        Step of the sliding window. If float, it represents the percentage of\n        the size of each time series and must be between 0 and 1. The step of\n        sliding window will be computed as\n        ``ceil(window_step * n_timestamps)``.\n    \n    \n    norm_mean \n    is not supported for initiallizing MBOP\n        \n\n    norm_std : bool (default = True)\n    is not supported for initiallizing MBOP\n\n    sparse : bool (default = True)\n        Return a sparse matrix if True, else return an array.\n\n    overlapping : bool (default = True)\n        If True, time points may belong to two bins when decreasing the size\n        of the subsequence with the Piecewise Aggregate Approximation\n        algorithm. If False, each time point belong to one single bin, but\n        the size of the bins may vary.\n\n    alphabet :\n    is not supported for initiallizing MBOP    \n    \n    \"\"\"\n    def __init__(self, n_channels=13, m_occur=0.01,\n                 window_size=4 , word_size=4 ,  n_bins =6, strategy = \"quantile\" ,  sparse  = False, \n                 numerosity_reduction=True, window_step=1 ,overlapping=True  ):      \n        self.window_size = window_size\n        self.word_size = word_size\n        self.n_bins = n_bins\n        self.strategy = strategy\n        self.numerosity_reduction = numerosity_reduction\n        self.window_step = window_step\n        self.sparse = sparse\n        self.overlapping = overlapping    # BOP parameters til here\n        self.m_occur= m_occur           # minimum of mean occurence columns with mean lower than minimum occur will be dropped out for size of feature \n        self.n_channels = n_channels\n        self.col_list=[]   #list of columns index with nontrivial occurrence called in self.reducer in self.fitting\n        self.MACHINES=[]   #stores n_channel Bop machines in this list\n        self.idces=[]\n        self.ft_X=None\n    \n        \n    def reducer (self, X,save_trans_X=False): \n        \"\"\"part of fitting. function used in self.fit\n        create instance variable reducing dimension of features.\n        \n        X :  3d arrary with (sample, time, channel)\"\"\"\n        temp_col_list=[]\n        trans_X_list=[]\n        for i in range(self.n_channels):\n            #acutal transform happens here.\n            #thus when fitting take save_trans_X= True then we can use self.recycle to recycle this result \n            temp_col=self.MACHINES[i].transform(X[:,:,i])    \n            self.col_list.append(temp_col.mean(axis=0)>self.m_occur)\n            if save_trans_X:\n                trans_X_list.append(temp_col[:,self.col_list[i]])                \n        if save_trans_X:\n            self.X_of_fit_list=trans_X_list\n        return self\n    \n        \n    def fit(self, X,save_trans_X=False): \n        \"\"\"\n        Fits BOP machines, given suitable dataframe.\n        There are n_channel number of different BOP Machines to fit.\n        Note that fit() actualy calculates result of fit_transform(X) \n        during it's process.\n        Hence if user is willing to save this calculation\n        take save_trans_X=True\n        then return of fit_transform(X) will be stored as instance\n        variable ft_X\n        \n        X : DataFrame with first column : index,\n                           last n_channel column: data of interest \n            For fit takes first and last n_channel-columns of data\n            and transform data with index by first column of X.\n             (n_samples*time rows, alpha) alpha: integer larger than n_channel.\n             \n            MBOP considers first column to be index and\n            last n_channel columns to be data of interest\n            fit will take first column as index of resultant dataframe\n            must make sure that X.iloc[:,0] is series of index and\n            last n_channel columns store data of interest\n        \n        Creates\n        -------\n        (when save_trans_X=True) self.tf_X : result of fit_transform(X)         \n        \"\"\"\n        self.MACHINES=[]  \n        self.col_list=[]                #resets col_list\n        data_3d=X.iloc[:,-self.n_channels :].to_numpy().reshape(-1,60,13)      #separating data and information array and reshaping by (n_sample , -1)\n        seq=(X.iloc[:,0].to_numpy().reshape(-1,60))[:,0]  #seq is 1d array \n        for i in range(self.n_channels):\n            self.MACHINES.append(BOP(\n                window_size=self.window_size, word_size=self.word_size,\n            n_bins=self.n_bins, strategy=self.strategy, sparse=self.sparse,\n            numerosity_reduction=self.numerosity_reduction,\n            window_step=self.window_step, overlapping=self.overlapping))\n            self.MACHINES[i].fit(data_3d[:,:,i])\n            print(\"{}-th machine fitted\".format(i))\n        print(\"reducing\")\n        self.reducer(data_3d,save_trans_X=save_trans_X) #makes object variable for transform (collecting index of nontrivial columns)\n        if save_trans_X:\n            self.ft_X=self.recycle(seq)\n            del self.X_of_fit_list\n        print(\"all fitted\")\n        return self\n    \n    def recycle(self,seq=None): \n        \"\"\"part of fitting\n           activates when parameter of fit is True\n        \"\"\"\n        print(\"fit_transform result has been saved as instance variable ft_X\")\n        return pd.DataFrame(np.concatenate(self.X_of_fit_list,axis=1),index=seq)\n    \n    def gods_sake(self):\n        print(\"help me\")\n        return self\n        \n    \n    def transform(self, X,y=None,train_transform=False):\n        \"\"\"\n        Transforms last n_channels-columns of X to (n_smaple, n_feature) DataFrame,\n        with index from first column of X.\n        If train_transform=True, method will try to find previously calculated\n        result while fitting.  \n        X : dataframe with first column holding index of X_new(reurn of transform) and\n            last-n_channels-columns holding data to transform.\n            Need to make sure first and last n_channel columns are correct\n            \n        y : ignored\n\n        train_transform : If is True and save_trans_X was True when fitting, \n                          retrieves transform result (Default  = False )\n                          deletes ft_X\n        Returns\n        ------\n        X_new : dataframe indexed with first column of X (n_samples, n_features)\n        \"\"\"\n        if train_transform:\n            if type(self.ft_X)!=type(None):\n                transform_X=self.ft_X.copy()\n                del self.ft_X\n                self.ft_X=None\n                print(\"previous calculation ft_X deleted\")\n                return transform_X\n\n        temp_col_list=[]\n        data_3d=X.iloc[:,-self.n_channels :].to_numpy().reshape(-1,60,13)\n        seq=(X.iloc[:,0].to_numpy().reshape(-1,60))[:,0]  #seq is 1d array \n        for i in range(self.n_channels):\n            temp_col=self.MACHINES[i].transform(data_3d[:,:,i])\n            print(\"{}-th channel finished\".format(i))\n            print(\"number of pure features of {} BOP={}\".format(i,self.col_list[i].shape))\n            temp_col_list.append(temp_col[:,self.col_list[i]])  #not temp_col list but some indexing because we are reducing by dropping trivial patterns\n            del temp_col\n        transform_X=np.concatenate(temp_col_list,axis=1)\n        print(\"shape={}\".format(transform_X.shape))\n        del temp_col_list\n        return pd.DataFrame(transform_X,index=seq)\n        \n    \n    \n    def fit_transform(self,X,y=None):\n        \"\"\"Faster than fitting and transforming\"\"\"\n        self.fit(X,save_trans_X=True)\n        transform_X=self.ft_X.copy()\n        del self.ft_X\n        return transform_X\n    \n    \n    \n    \n    \n    def refinement(self,trans_train_X,new_m_occur=0.011): \n        \"\"\"\n        method defined for search of better m_occur (larger than m_occur)\n        used to find larger m_occur parameter i.e. larger refinement , smaller dimension of feature.\n        mostly 1percent works fine\n        \n        trans_train_X : The transform of X used to fit BOPs.i.e. fit_transform (X).\n                        Need to input transform of exactly same dataframe that \n                        has been used for fitting\n        new_m_occur  :  float larger than self.m_occur or list of such floats.\n                        \n        Creates\n        -------\n        idces : list of indices(Int64Index) corresponding to inputed list or even single new_m_occur (pandas.core.indexes.numeric.Int64Index)\n        \n        \n        Example\n        --------\n        Being Int64Index and being a subindex of columns of fit_transform(X), can input directly.\n        >>train_X=fit_transform(train_X)\n        >>test_X=transform(test_data)\n        >>for i in self.idces:\n        >>    clf.fit(train_X[i],train_y)\n        >>    clf.score(test_X[i],test_y)\n        \"\"\"\n        self.idces=[]\n        try:\n            for i in new_m_occur:\n                if i<self.m_occur:\n                    print(\"new minimum occurrence has to be larger than previous one\")\n                    pass\n                else:\n                    self.idces.append((trans_train_X.mean()[(trans_train_X.mean()>i)\n                                                  ]).index)\n            print(\"instance variable created: idces list of new minimum mean occurence\")\n        except TypeError:\n            if new_m_occur<self.m_occur:\n                print(\"new minimum occurrence has to be larger than previous one\")\n                return None\n            else:\n                print(\"instance variable created: list with single new minimum mean occurence\")\n                self.idces.append((trans_train_X.mean()[(trans_train_X.mean()>new_m_occur)\n                                                                              ]).index)","metadata":{"execution":{"iopub.status.busy":"2022-09-16T04:44:59.326240Z","iopub.execute_input":"2022-09-16T04:44:59.326617Z","iopub.status.idle":"2022-09-16T04:45:14.082158Z","shell.execute_reply.started":"2022-09-16T04:44:59.326584Z","shell.execute_reply":"2022-09-16T04:45:14.080489Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting pyts\n  Downloading pyts-0.12.0-py3-none-any.whl (2.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hRequirement already satisfied: scipy>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pyts) (1.7.3)\nRequirement already satisfied: numpy>=1.17.5 in /opt/conda/lib/python3.7/site-packages (from pyts) (1.21.6)\nRequirement already satisfied: numba>=0.48.0 in /opt/conda/lib/python3.7/site-packages (from pyts) (0.55.1)\nRequirement already satisfied: scikit-learn>=0.22.1 in /opt/conda/lib/python3.7/site-packages (from pyts) (1.0.2)\nRequirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.7/site-packages (from pyts) (1.1.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.48.0->pyts) (0.38.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.48.0->pyts) (59.8.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22.1->pyts) (3.1.0)\nInstalling collected packages: pyts\nSuccessfully installed pyts-0.12.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"df = load_raw_data('train')\ny = load_label('train')","metadata":{"execution":{"iopub.status.busy":"2022-09-16T04:45:14.086809Z","iopub.execute_input":"2022-09-16T04:45:14.087191Z","iopub.status.idle":"2022-09-16T04:45:22.657341Z","shell.execute_reply.started":"2022-09-16T04:45:14.087156Z","shell.execute_reply":"2022-09-16T04:45:22.656193Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.pipeline import make_union\nfrom sklearn.metrics import classification_report\ncv_scores = []\n\nextractors = [CorrExtractor(), ElementaryExtractor(), TsfreshExtractor(), MBOP()]\nextractor = make_union(*extractors)\n\nfor mask_df_val, mask_y_val in group_splitter(df, nfold=5, random_state=42):\n    df_train, y_train = df[~mask_df_val], y[~mask_y_val]\n    df_val, y_val = df[mask_df_val], y[mask_y_val]\n    \n    X_train = extractor.fit_transform(df_train)\n    X_val = extractor.transform(df_val)\n    print(X_train.shape, X_val.shape)\n    \n    clf = LGBMClassifier(num_leaves=31, max_depth=-1, n_estimators=100, random_state=42)\n    clf.fit(X_train, y_train)\n    print(evaluate(clf, X_train, y_train))\n    print(evaluate(clf, X_val, y_val))\n    print(classification_report(y_val, (clf.predict(X_val) >= 0.5).astype(int), digits=4 ))\n    \n    cv_scores.append(evaluate(clf, X_val, y_val))\nprint(f'5-fold CV score: {np.mean(cv_scores):.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-09-16T04:45:22.658758Z","iopub.execute_input":"2022-09-16T04:45:22.659071Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: divide by zero encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:161: RuntimeWarning: invalid value encountered in true_divide\nFeature Extraction: 100%|██████████| 10/10 [02:09<00:00, 12.91s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:59<00:00,  5.98s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:35<00:00,  9.52s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:54<00:00, 11.43s/it]\nFeature Extraction: 100%|██████████| 10/10 [04:34<00:00, 27.41s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:08<00:00,  6.87s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:58<00:00,  5.85s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:11<00:00, 13.17s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:11<00:00,  1.14s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:08<00:00, 12.87s/it]\nFeature Extraction: 100%|██████████| 10/10 [04:28<00:00, 26.86s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:01<00:00, 12.16s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:39<00:00, 15.93s/it]\n","output_type":"stream"},{"name":"stdout","text":"0-th machine fitted\n1-th machine fitted\n2-th machine fitted\n3-th machine fitted\n4-th machine fitted\n5-th machine fitted\n6-th machine fitted\n7-th machine fitted\n8-th machine fitted\n9-th machine fitted\n10-th machine fitted\n11-th machine fitted\n12-th machine fitted\nreducing\nfit_transform result has been saved as instance variable ft_X\nall fitted\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: divide by zero encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:161: RuntimeWarning: invalid value encountered in true_divide\nFeature Extraction: 100%|██████████| 10/10 [00:33<00:00,  3.31s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:24<00:00,  2.40s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:30<00:00,  3.02s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:09<00:00,  6.92s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:18<00:00,  1.84s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:15<00:00,  1.57s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:34<00:00,  3.49s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:03<00:00,  3.12it/s]\nFeature Extraction: 100%|██████████| 10/10 [00:34<00:00,  3.41s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:06<00:00,  6.66s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:31<00:00,  3.11s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:40<00:00,  4.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"0-th channel finished\nnumber of pure features of 0 BOP=(74,)\n1-th channel finished\nnumber of pure features of 1 BOP=(76,)\n2-th channel finished\nnumber of pure features of 2 BOP=(130,)\n3-th channel finished\nnumber of pure features of 3 BOP=(75,)\n4-th channel finished\nnumber of pure features of 4 BOP=(972,)\n5-th channel finished\nnumber of pure features of 5 BOP=(310,)\n6-th channel finished\nnumber of pure features of 6 BOP=(74,)\n7-th channel finished\nnumber of pure features of 7 BOP=(74,)\n8-th channel finished\nnumber of pure features of 8 BOP=(79,)\n9-th channel finished\nnumber of pure features of 9 BOP=(77,)\n10-th channel finished\nnumber of pure features of 10 BOP=(1102,)\n11-th channel finished\nnumber of pure features of 11 BOP=(72,)\n12-th channel finished\nnumber of pure features of 12 BOP=(1287,)\nshape=(5151, 406)\n(20817, 909) (5151, 909)\n0.997048055973935\n0.9679046719638748\n              precision    recall  f1-score   support\n\n           0       0.93      0.88      0.91      2592\n           1       0.89      0.94      0.91      2559\n\n    accuracy                           0.91      5151\n   macro avg       0.91      0.91      0.91      5151\nweighted avg       0.91      0.91      0.91      5151\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: divide by zero encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:161: RuntimeWarning: invalid value encountered in true_divide\nFeature Extraction: 100%|██████████| 10/10 [02:18<00:00, 13.87s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:02<00:00,  6.25s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:39<00:00,  9.98s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:04<00:00, 12.47s/it]\nFeature Extraction: 100%|██████████| 10/10 [04:52<00:00, 29.23s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:15<00:00,  7.52s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:02<00:00,  6.25s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:20<00:00, 14.07s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:12<00:00,  1.20s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:18<00:00, 13.82s/it]\nFeature Extraction: 100%|██████████| 10/10 [04:39<00:00, 27.95s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:10<00:00, 13.07s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:46<00:00, 16.69s/it]\n","output_type":"stream"},{"name":"stdout","text":"0-th machine fitted\n1-th machine fitted\n2-th machine fitted\n3-th machine fitted\n4-th machine fitted\n5-th machine fitted\n6-th machine fitted\n7-th machine fitted\n8-th machine fitted\n9-th machine fitted\n10-th machine fitted\n11-th machine fitted\n12-th machine fitted\nreducing\nfit_transform result has been saved as instance variable ft_X\nall fitted\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: divide by zero encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:161: RuntimeWarning: invalid value encountered in true_divide\nFeature Extraction: 100%|██████████| 10/10 [00:28<00:00,  2.87s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:12<00:00,  1.28s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:21<00:00,  2.12s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:26<00:00,  2.65s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:00<00:00,  6.09s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:12<00:00,  1.27s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:29<00:00,  2.90s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:02<00:00,  3.50it/s]\nFeature Extraction: 100%|██████████| 10/10 [00:28<00:00,  2.84s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:57<00:00,  5.76s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:27<00:00,  2.73s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:35<00:00,  3.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"0-th channel finished\nnumber of pure features of 0 BOP=(76,)\n1-th channel finished\nnumber of pure features of 1 BOP=(81,)\n2-th channel finished\nnumber of pure features of 2 BOP=(132,)\n3-th channel finished\nnumber of pure features of 3 BOP=(85,)\n4-th channel finished\nnumber of pure features of 4 BOP=(775,)\n5-th channel finished\nnumber of pure features of 5 BOP=(164,)\n6-th channel finished\nnumber of pure features of 6 BOP=(75,)\n7-th channel finished\nnumber of pure features of 7 BOP=(81,)\n8-th channel finished\nnumber of pure features of 8 BOP=(79,)\n9-th channel finished\nnumber of pure features of 9 BOP=(81,)\n10-th channel finished\nnumber of pure features of 10 BOP=(1065,)\n11-th channel finished\nnumber of pure features of 11 BOP=(73,)\n12-th channel finished\nnumber of pure features of 12 BOP=(1290,)\nshape=(4599, 406)\n(21369, 909) (4599, 909)\n0.9967701620475397\n0.9665739281037276\n              precision    recall  f1-score   support\n\n           0       0.94      0.88      0.91      2412\n           1       0.88      0.93      0.90      2187\n\n    accuracy                           0.91      4599\n   macro avg       0.91      0.91      0.91      4599\nweighted avg       0.91      0.91      0.91      4599\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: divide by zero encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:161: RuntimeWarning: invalid value encountered in true_divide\nFeature Extraction: 100%|██████████| 10/10 [02:05<00:00, 12.53s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:54<00:00,  5.48s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:31<00:00,  9.11s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:51<00:00, 11.15s/it]\nFeature Extraction: 100%|██████████| 10/10 [04:19<00:00, 25.96s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:07<00:00,  6.71s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:56<00:00,  5.70s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:06<00:00, 12.69s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:02<00:00, 12.21s/it]\nFeature Extraction: 100%|██████████| 10/10 [04:05<00:00, 24.56s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:02<00:00, 12.21s/it]\nFeature Extraction: 100%|██████████| 10/10 [02:34<00:00, 15.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"0-th machine fitted\n1-th machine fitted\n2-th machine fitted\n3-th machine fitted\n4-th machine fitted\n5-th machine fitted\n6-th machine fitted\n7-th machine fitted\n8-th machine fitted\n9-th machine fitted\n10-th machine fitted\n11-th machine fitted\n12-th machine fitted\nreducing\nfit_transform result has been saved as instance variable ft_X\nall fitted\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: invalid value encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:146: RuntimeWarning: divide by zero encountered in true_divide\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:161: RuntimeWarning: invalid value encountered in true_divide\nFeature Extraction: 100%|██████████| 10/10 [00:37<00:00,  3.76s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:16<00:00,  1.64s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:27<00:00,  2.79s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:32<00:00,  3.30s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:17<00:00,  7.79s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:20<00:00,  2.03s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:17<00:00,  1.75s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:37<00:00,  3.77s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:03<00:00,  2.87it/s]\nFeature Extraction: 100%|██████████| 10/10 [00:36<00:00,  3.65s/it]\nFeature Extraction: 100%|██████████| 10/10 [01:14<00:00,  7.50s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:36<00:00,  3.66s/it]\nFeature Extraction: 100%|██████████| 10/10 [00:46<00:00,  4.64s/it]\n","output_type":"stream"},{"name":"stdout","text":"0-th channel finished\nnumber of pure features of 0 BOP=(75,)\n1-th channel finished\nnumber of pure features of 1 BOP=(81,)\n2-th channel finished\nnumber of pure features of 2 BOP=(127,)\n3-th channel finished\nnumber of pure features of 3 BOP=(84,)\n4-th channel finished\nnumber of pure features of 4 BOP=(994,)\n5-th channel finished\nnumber of pure features of 5 BOP=(325,)\n6-th channel finished\nnumber of pure features of 6 BOP=(74,)\n7-th channel finished\nnumber of pure features of 7 BOP=(81,)\n8-th channel finished\nnumber of pure features of 8 BOP=(79,)\n9-th channel finished\nnumber of pure features of 9 BOP=(81,)\n10-th channel finished\nnumber of pure features of 10 BOP=(1115,)\n11-th channel finished\nnumber of pure features of 11 BOP=(71,)\n12-th channel finished\nnumber of pure features of 12 BOP=(1289,)\nshape=(6004, 406)\n(19964, 909) (6004, 909)\n0.9977424039223814\n0.9510285631120259\n              precision    recall  f1-score   support\n\n           0       0.89      0.87      0.88      2789\n           1       0.89      0.91      0.90      3215\n\n    accuracy                           0.89      6004\n   macro avg       0.89      0.89      0.89      6004\nweighted avg       0.89      0.89      0.89      6004\n\n","output_type":"stream"}]},{"cell_type":"code","source":"clf = LGBMClassifier(num_leaves=31, max_depth=4, n_estimators=100)\n\ndf_train_final = df\ny_train_final = y\nX_train_final = extractor.fit_transform(df_train_final)\nclf.fit(X_train_final, y_train_final)\n\ndf_test_final = load_raw_data('test')\nX_test_final = extractor.transform(df_test_final)\ny_pred = clf.predict_proba(X_test_final)[:, 1]\nsubmit(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}