{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"input_path = '../input/tabular-playground-series-apr-2022/'\noutput_path = './'","metadata":{"_uuid":"418a416b-3a53-4812-a723-fd867fcfa0ce","_cell_guid":"e9ca7ffd-04b4-4306-be89-47e9820808ff","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-21T06:40:25.303563Z","iopub.execute_input":"2022-09-21T06:40:25.303943Z","iopub.status.idle":"2022-09-21T06:40:25.308824Z","shell.execute_reply.started":"2022-09-21T06:40:25.303914Z","shell.execute_reply":"2022-09-21T06:40:25.307790Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\ndef load_raw_data(train_or_test='train'):\n    file_name = f'{input_path}/{train_or_test}.csv'\n    df = pd.read_csv(file_name)\n    return df\n\ndef load_label(train_or_test='train'):\n    file_name = input_path + ('train_labels.csv' if train_or_test=='train' else 'sample_submission.csv')\n    df = pd.read_csv(file_name)\n    return df['state'].values\n\ndef competition_metric(y_true, y_score):\n    return roc_auc_score(y_true, y_score)\n\ndef evaluate(model, X, y):\n    return competition_metric(y, model.predict_proba(X)[:, 1])\n\ndef submit(arr):\n    df = pd.read_csv(f'{input_path}/sample_submission.csv')\n    df['state'] = arr\n    df.to_csv(f'{output_path}/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-21T06:40:25.315646Z","iopub.execute_input":"2022-09-21T06:40:25.316538Z","iopub.status.idle":"2022-09-21T06:40:25.324684Z","shell.execute_reply.started":"2022-09-21T06:40:25.316503Z","shell.execute_reply":"2022-09-21T06:40:25.323750Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass ResNetModel(keras.Model):\n    def __init__(self):\n        super(ResNetModel, self).__init__()\n        self.fns = [\n            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)), \n            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.Conv1D(filters=20, kernel_size=8, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.AveragePooling1D(2),\n            \n            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.Conv1D(filters=20, kernel_size=6, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.AveragePooling1D(2),\n            \n            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.Conv1D(filters=20, kernel_size=4, padding='same', activation='elu', kernel_regularizer=keras.regularizers.L2(1e-3)),\n            keras.layers.AveragePooling1D(3),\n            \n            keras.layers.GlobalAveragePooling1D(),\n            keras.layers.Dense(1, activation='sigmoid')\n        ]\n        self.bns = [\n            keras.layers.BatchNormalization(), \n            keras.layers.BatchNormalization(), \n            \n            keras.layers.BatchNormalization(), \n            keras.layers.BatchNormalization(), \n            \n            keras.layers.BatchNormalization(), \n            keras.layers.BatchNormalization(), \n            \n            keras.layers.BatchNormalization(), \n            keras.layers.BatchNormalization(), \n        ]\n        \n    def call(self, inputs):\n        outputs = inputs\n        \n        outputs = self.fns[0](outputs)\n        res = outputs\n        res = self.fns[1](res)\n        res = self.fns[2](res)\n        outputs += res\n        outputs = self.fns[3](outputs)\n        \n        outputs = self.fns[4](outputs)\n        res = outputs\n        res = self.fns[5](res)\n        res = self.fns[6](res)\n        outputs += res\n        outputs = self.fns[7](outputs)\n        \n        outputs = self.fns[8](outputs)\n        res = outputs\n        res = self.fns[9](res)\n        res = self.fns[10](res)\n        outputs += res\n        outputs = self.fns[11](outputs)\n        \n        outputs = self.fns[-2](outputs)\n        outputs = self.fns[-1](outputs)\n        \n        return outputs\n    \n    def predict_proba(self, X):\n        return np.concatenate([1-self.predict(X), self.predict(X)], axis=1)\n\ndef random_sensor_swap(x, y, random_state=None):\n    rng = np.random.default_rng(random_state)\n    p_swap = 0.5\n    indices = rng.choice(np.arange(x.shape[0]), int(p_swap*x.shape[0]), replace=False)\n    x_aug, y_aug = x[indices], y[indices]\n    swap_codes = rng.integers(0, 13, (x_aug.shape[0], 2))\n    for i in range(x_aug.shape[0]):\n        a, b = swap_codes[i]\n        x_aug[i, :, [a, b]] = x_aug[i, :, [b, a]]\n    x = np.concatenate([x, x_aug], axis=0)\n    y = np.concatenate([y, y_aug], axis=0)\n    return x, y\n\ndef group_splitter(df, nfold=5, random_state=None):\n    subject_nums = df['subject'].unique()\n    rng = np.random.default_rng(random_state)\n    subject_to_setnum = rng.integers(0, nfold, subject_nums.shape[0])\n    for i in range(nfold):\n        val_subjects = subject_nums[subject_to_setnum == i]\n        mask_df_val = df['subject'].isin(val_subjects)\n        mask_y_val = mask_df_val.iloc[::60]\n        yield mask_df_val, mask_y_val\n\n        \nclass MyDataAugmenter():\n    def fit(self, X, y):\n        return self\n    \n    def transform(self, X, y):\n        return X, y\n\nclass DF2arr(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        return X.loc[:, 'sensor_00':'sensor_12'].values.reshape(-1, 60, 13)\n    \n    \nclass MyPreprocessor(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X = normalize(X)\n        return X\n    \ndef normalize(x):\n    x = x / (np.linalg.norm(x, axis=1, keepdims=True) + 1e-10)\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-09-21T06:40:25.326797Z","iopub.execute_input":"2022-09-21T06:40:25.327309Z","iopub.status.idle":"2022-09-21T06:40:25.357489Z","shell.execute_reply.started":"2022-09-21T06:40:25.327269Z","shell.execute_reply":"2022-09-21T06:40:25.356392Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass RNNThickModel(keras.Model):\n    def __init__(self):\n        super(RNNThickModel, self).__init__()\n        self.fns = [\n            keras.layers.LSTM(\n                units=256, \n                kernel_regularizer=keras.regularizers.L2(2e-3),\n#                 recurrent_regularizer=keras.regularizers.L2(1e-5),\n#                 dropout=0.05,\n#                 recurrent_dropout=0.01,\n                return_sequences=True\n            ),\n            keras.layers.LSTM(\n                units=128,\n                kernel_regularizer=keras.regularizers.L2(2e-3),\n#                 recurrent_regularizer=keras.regularizers.L2(1e-5),\n#                 dropout=0.05,\n#                 recurrent_dropout=0.01,\n            ),\n            keras.layers.Dense(units=32, activation='elu'),\n            keras.layers.Dense(units=1, activation='sigmoid')\n        ]\n    \n    def call(self, inputs):\n        outputs = inputs\n        for layer in self.fns:\n            outputs = layer(outputs)\n        return outputs\n    \n    def predict_proba(self, X):\n        return np.concatenate([1-self.predict(X), self.predict(X)], axis=1)\n\n    \nclass MySoftVoter():\n    def __init__(self, models, weights=None):\n        self.models = models\n        if weights is None:\n            weights = np.ones((len(models), ))\n        weights /= np.sum(weights)\n        self.weights = weights\n    \n    def predict(self, X):\n        result = np.zeros((X.shape[0], ), dtype=X.dtype)\n        for model, weight in zip(self.models, self.weights):\n            add = model.predict(X)\n            if len(add.shape) > 1:\n                add = add[:, 0]\n            result += add * weight\n        return result\n    \n    def predict_proba(self, X):\n        return np.stack([1-self.predict(X), self.predict(X)], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-21T06:40:25.359089Z","iopub.execute_input":"2022-09-21T06:40:25.359426Z","iopub.status.idle":"2022-09-21T06:40:25.373166Z","shell.execute_reply.started":"2022-09-21T06:40:25.359394Z","shell.execute_reply":"2022-09-21T06:40:25.372226Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.metrics import classification_report\ncv_scores = []\n\ndf = load_raw_data('train')\ny = load_label('train')\nX = DF2arr().transform(df)\nsubj_nums = df['subject']\n\npreprocessor = make_pipeline(DF2arr(), MyPreprocessor())\n\nkeras.backend.clear_session()\ntf.random.set_seed(42)\n\ncallbacks = [\n    keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True)\n]\nfor mask_df_val, mask_y_val in group_splitter(df, nfold=5, random_state=42):\n    df_train, df_val = df[~mask_df_val], df[mask_df_val]\n    y_train, y_val = y[~mask_y_val], y[mask_y_val]\n    for mask_df_v, mask_y_v in group_splitter(df_train, nfold=5, random_state=42):\n        df_t, df_v = df_train[~mask_df_v], df_train[mask_df_v]\n        y_t, y_v = y_train[~mask_y_v], y_train[mask_y_v]\n\n    X_t = preprocessor.fit_transform(df_t)\n    X_v = preprocessor.transform(df_v)\n    X_val = preprocessor.transform(df_val)\n\n    models = [RNNThickModel() for _ in range(3)] + [ResNetModel() for _ in range(3)]\n    weights = []\n    for model in models:\n        with tf.device('gpu:0'):\n            model.compile(\n                loss='binary_crossentropy', \n                metrics=['AUC'],\n                optimizer=keras.optimizers.Adam(1e-3))\n            model.fit(\n                X_t, y_t, \n                batch_size=1024,\n                epochs=500, \n                callbacks=callbacks,\n                validation_data=(X_v, y_v),\n                verbose=0\n            )\n            weights.append( model.evaluate(X_val, y_val)[-1] - 0.5 )\n\n    model = MySoftVoter(models, weights)\n    print(evaluate(model, X_val, y_val))\n    print(classification_report(y_val, (model.predict(X_val) >= 0.5).astype(int), digits=4 ))\n    \n    cv_scores.append(evaluate(model, X_val, y_val))\nprint(f'5-fold CV score: {np.mean(cv_scores):.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-09-21T06:40:25.555080Z","iopub.execute_input":"2022-09-21T06:40:25.555977Z","iopub.status.idle":"2022-09-21T08:18:24.336556Z","shell.execute_reply.started":"2022-09-21T06:40:25.555936Z","shell.execute_reply":"2022-09-21T08:18:24.335385Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"161/161 [==============================] - 1s 5ms/step - loss: 0.3068 - auc: 0.9559\n161/161 [==============================] - 1s 5ms/step - loss: 0.6760 - auc: 0.5822\n161/161 [==============================] - 1s 5ms/step - loss: 0.3067 - auc: 0.9555\n161/161 [==============================] - 1s 3ms/step - loss: 0.3549 - auc: 0.9472\n161/161 [==============================] - 1s 3ms/step - loss: 0.3604 - auc: 0.9472\n161/161 [==============================] - 1s 4ms/step - loss: 0.3248 - auc: 0.9629\n0.9690720297280476\n              precision    recall  f1-score   support\n\n           0     0.9180    0.9024    0.9101      2592\n           1     0.9028    0.9183    0.9105      2559\n\n    accuracy                         0.9103      5151\n   macro avg     0.9104    0.9104    0.9103      5151\nweighted avg     0.9104    0.9103    0.9103      5151\n\n144/144 [==============================] - 1s 7ms/step - loss: 0.3679 - auc: 0.9305\n144/144 [==============================] - 1s 5ms/step - loss: 0.3320 - auc: 0.9504\n144/144 [==============================] - 1s 5ms/step - loss: 0.3391 - auc: 0.9449\n144/144 [==============================] - 1s 4ms/step - loss: 0.4199 - auc: 0.9395\n144/144 [==============================] - 1s 4ms/step - loss: 0.4001 - auc: 0.9394\n144/144 [==============================] - 1s 4ms/step - loss: 0.3690 - auc: 0.9563\n0.959645075946286\n              precision    recall  f1-score   support\n\n           0     0.8936    0.9084    0.9009      2412\n           1     0.8971    0.8807    0.8888      2187\n\n    accuracy                         0.8952      4599\n   macro avg     0.8953    0.8945    0.8948      4599\nweighted avg     0.8952    0.8952    0.8951      4599\n\n188/188 [==============================] - 1s 5ms/step - loss: 0.6732 - auc: 0.5945\n188/188 [==============================] - 1s 5ms/step - loss: 0.6678 - auc: 0.6173\n188/188 [==============================] - 1s 5ms/step - loss: 0.6578 - auc: 0.6854\n188/188 [==============================] - 1s 4ms/step - loss: 0.3275 - auc: 0.9604\n188/188 [==============================] - 1s 6ms/step - loss: 0.3693 - auc: 0.9448\n188/188 [==============================] - 1s 5ms/step - loss: 0.3420 - auc: 0.9569\n0.9664075765323334\n              precision    recall  f1-score   support\n\n           0     0.8903    0.9021    0.8962      2789\n           1     0.9141    0.9036    0.9088      3215\n\n    accuracy                         0.9029      6004\n   macro avg     0.9022    0.9028    0.9025      6004\nweighted avg     0.9030    0.9029    0.9029      6004\n\n165/165 [==============================] - 1s 5ms/step - loss: 0.6637 - auc: 0.6147\n165/165 [==============================] - 1s 5ms/step - loss: 0.6829 - auc: 0.5826\n165/165 [==============================] - 1s 5ms/step - loss: 0.2780 - auc: 0.9639\n165/165 [==============================] - 1s 4ms/step - loss: 0.3795 - auc: 0.9424\n165/165 [==============================] - 1s 3ms/step - loss: 0.3459 - auc: 0.9490\n165/165 [==============================] - 1s 4ms/step - loss: 0.3783 - auc: 0.9421\n0.9625039871483334\n              precision    recall  f1-score   support\n\n           0     0.8865    0.8959    0.8912      2564\n           1     0.8997    0.8907    0.8952      2690\n\n    accuracy                         0.8932      5254\n   macro avg     0.8931    0.8933    0.8932      5254\nweighted avg     0.8933    0.8932    0.8932      5254\n\n155/155 [==============================] - 2s 6ms/step - loss: 0.2994 - auc: 0.9571\n155/155 [==============================] - 1s 5ms/step - loss: 0.3036 - auc: 0.9569\n155/155 [==============================] - 1s 5ms/step - loss: 0.2948 - auc: 0.9587\n155/155 [==============================] - 1s 4ms/step - loss: 0.3709 - auc: 0.9435\n155/155 [==============================] - 1s 4ms/step - loss: 0.3281 - auc: 0.9618\n155/155 [==============================] - 1s 4ms/step - loss: 0.3310 - auc: 0.9585\n0.9704509467693688\n              precision    recall  f1-score   support\n\n           0     0.9251    0.8983    0.9115      2597\n           1     0.8917    0.9200    0.9056      2363\n\n    accuracy                         0.9087      4960\n   macro avg     0.9084    0.9092    0.9086      4960\nweighted avg     0.9092    0.9087    0.9087      4960\n\n5-fold CV score: 0.9656\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test_final = load_raw_data('test')\n\nX_train = preprocessor.fit_transform(df_train)\nX_val = preprocessor.transform(df_val)\nX_test_final = preprocessor.transform(df_test_final)\n\nmodels = [RNNThickModel() for _ in range(3)] + [ResNetModel() for _ in range(3)]\nweights = []\nfor model in models:\n    with tf.device('gpu:0'):\n        model.compile(\n            loss='binary_crossentropy', \n            metrics=['AUC'],\n            optimizer=keras.optimizers.Adam(1e-3))\n        model.fit(\n            X_train, y_train, \n            epochs=500, \n            batch_size=1024,\n            callbacks=callbacks,\n            validation_data=(X_val, y_val),\n            verbose=0\n        )\n        weights.append( model.evaluate(X_val, y_val)[-1] - 0.5 )\n    \nmodel = MySoftVoter(models)\ny_pred = model.predict(X_test_final)\nsubmit(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-09-21T08:18:24.341246Z","iopub.execute_input":"2022-09-21T08:18:24.343811Z","iopub.status.idle":"2022-09-21T08:18:29.250576Z","shell.execute_reply.started":"2022-09-21T08:18:24.343772Z","shell.execute_reply":"2022-09-21T08:18:29.249391Z"},"trusted":true},"execution_count":14,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/4150007112.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         )\n\u001b[1;32m     19\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2788\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2791\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n","\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."],"ename":"RuntimeError","evalue":"You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.","output_type":"error"}]}]}